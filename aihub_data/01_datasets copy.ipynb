{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c41f5e0d",
   "metadata": {},
   "source": [
    "# 민사법 데이터셋 빌더 (JSON 원본 보존)\n",
    "\n",
    "이 노트북은 ZIP 파일 내 JSON 데이터를 **원본 구조 그대로** HuggingFace Dataset으로 변환합니다.\n",
    "- 원본 JSON 필드 모두 보존\n",
    "- 최소한의 정규화만 적용 (Arrow/Parquet 호환성)\n",
    "- 타입별 자동 분류 및 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1981ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.10.18 environment at: /mnt/c/Users/LANDSOFT/Documents/dev/law/.venv\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 853ms\u001b[0m\u001b[0m\n",
      "\u001b[2mAudited \u001b[1m1 package\u001b[0m \u001b[2min 853ms\u001b[0m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f4f352f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/c/Users/LANDSOFT/Documents/dev/law/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import zipfile\n",
    "import json\n",
    "from datasets import Dataset\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "052eebc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = \"/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e304eb91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22 zip files.\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/01.원천데이터/TS_01. 민사법_002. 법령.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/01.원천데이터/TS_01. 민사법_003. 심결례.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/01.원천데이터/TS_01. 민사법_001. 판결문.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/01.원천데이터/TS_01. 민사법_004. 유권해석.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_01. 민사법_001. 판결문_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_01. 민사법_001. 판결문_0002. 요약.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_01. 민사법_002. 법령_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_01. 민사법_003. 심결례_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_01. 민사법_003. 심결례_0002. 요약.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_01. 민사법_004. 유권해석_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Training/02.라벨링데이터/TL_01. 민사법_004. 유권해석_0002. 요약.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_01. 민사법_001. 판결문.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_01. 민사법_002. 법령.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_01. 민사법_003. 심결례.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/01.원천데이터/VS_01. 민사법_004. 유권해석.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_01. 민사법_001. 판결문_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_01. 민사법_001. 판결문_0002. 요약.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_01. 민사법_002. 법령_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_01. 민사법_003. 심결례_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_01. 민사법_003. 심결례_0002. 요약.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_01. 민사법_004. 유권해석_0001. 질의응답.zip\n",
      "/mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/3.개방데이터/1.데이터/Validation/02.라벨링데이터/VL_01. 민사법_004. 유권해석_0002. 요약.zip\n"
     ]
    }
   ],
   "source": [
    "# BASE_DIR 아래 모든 zip file 경로 수집\n",
    "zip_files = list(Path(BASE_DIR).rglob(\"*.zip\"))\n",
    "print(f\"Found {len(zip_files)} zip files.\")\n",
    "for zip_file in zip_files:\n",
    "    print(zip_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6273211e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ZIP 파일 분류:\n",
      "\n",
      "train_authoritative_interpretation_qa: 1 files\n",
      "  - TL_01. 민사법_004. 유권해석_0001. 질의응답.zip\n",
      "\n",
      "train_authoritative_interpretation_source: 1 files\n",
      "  - TS_01. 민사법_004. 유권해석.zip\n",
      "\n",
      "train_authoritative_interpretation_summary: 1 files\n",
      "  - TL_01. 민사법_004. 유권해석_0002. 요약.zip\n",
      "\n",
      "train_precedent_qa: 1 files\n",
      "  - TL_01. 민사법_001. 판결문_0001. 질의응답.zip\n",
      "\n",
      "train_precedent_source: 1 files\n",
      "  - TS_01. 민사법_001. 판결문.zip\n",
      "\n",
      "train_precedent_summary: 1 files\n",
      "  - TL_01. 민사법_001. 판결문_0002. 요약.zip\n",
      "\n",
      "train_statute_qa: 1 files\n",
      "  - TL_01. 민사법_002. 법령_0001. 질의응답.zip\n",
      "\n",
      "train_statute_source: 1 files\n",
      "  - TS_01. 민사법_002. 법령.zip\n",
      "\n",
      "train_trial_decision_qa: 1 files\n",
      "  - TL_01. 민사법_003. 심결례_0001. 질의응답.zip\n",
      "\n",
      "train_trial_decision_source: 1 files\n",
      "  - TS_01. 민사법_003. 심결례.zip\n",
      "\n",
      "train_trial_decision_summary: 1 files\n",
      "  - TL_01. 민사법_003. 심결례_0002. 요약.zip\n",
      "\n",
      "validation_authoritative_interpretation_qa: 1 files\n",
      "  - VL_01. 민사법_004. 유권해석_0001. 질의응답.zip\n",
      "\n",
      "validation_authoritative_interpretation_source: 1 files\n",
      "  - VS_01. 민사법_004. 유권해석.zip\n",
      "\n",
      "validation_authoritative_interpretation_summary: 1 files\n",
      "  - VL_01. 민사법_004. 유권해석_0002. 요약.zip\n",
      "\n",
      "validation_precedent_qa: 1 files\n",
      "  - VL_01. 민사법_001. 판결문_0001. 질의응답.zip\n",
      "\n",
      "validation_precedent_source: 1 files\n",
      "  - VS_01. 민사법_001. 판결문.zip\n",
      "\n",
      "validation_precedent_summary: 1 files\n",
      "  - VL_01. 민사법_001. 판결문_0002. 요약.zip\n",
      "\n",
      "validation_statute_qa: 1 files\n",
      "  - VL_01. 민사법_002. 법령_0001. 질의응답.zip\n",
      "\n",
      "validation_statute_source: 1 files\n",
      "  - VS_01. 민사법_002. 법령.zip\n",
      "\n",
      "validation_trial_decision_qa: 1 files\n",
      "  - VL_01. 민사법_003. 심결례_0001. 질의응답.zip\n",
      "\n",
      "validation_trial_decision_source: 1 files\n",
      "  - VS_01. 민사법_003. 심결례.zip\n",
      "\n",
      "validation_trial_decision_summary: 1 files\n",
      "  - VL_01. 민사법_003. 심결례_0002. 요약.zip\n"
     ]
    }
   ],
   "source": [
    "# ZIP 파일 타입별 분류 및 JSON 구조 탐색\n",
    "import zipfile\n",
    "import json\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "zip_by_type = defaultdict(list)\n",
    "\n",
    "for zpath in zip_files:\n",
    "    name = zpath.name\n",
    "    # 파일명 패턴 파싱: TS/TL/VS/VL + 데이터타입(판결문/법령/심결례/유권해석) + 태스크(질의응답/요약)\n",
    "    if \"판결문\" in name:\n",
    "        data_type = \"precedent\"\n",
    "    elif \"법령\" in name:\n",
    "        data_type = \"statute\"\n",
    "    elif \"심결례\" in name:\n",
    "        data_type = \"trial_decision\"\n",
    "    elif \"유권해석\" in name:\n",
    "        data_type = \"authoritative_interpretation\"\n",
    "    else:\n",
    "        data_type = \"unknown\"\n",
    "    \n",
    "    if \"질의응답\" in name:\n",
    "        task_type = \"qa\"\n",
    "    elif \"요약\" in name:\n",
    "        task_type = \"summary\"\n",
    "    else:\n",
    "        task_type = \"source\"\n",
    "    \n",
    "    split = \"train\" if (\"TL_\" in name or \"TS_\" in name) else \"validation\"\n",
    "    \n",
    "    key = f\"{split}_{data_type}_{task_type}\"\n",
    "    zip_by_type[key].append(zpath)\n",
    "\n",
    "print(\"ZIP 파일 분류:\")\n",
    "for key, paths in sorted(zip_by_type.items()):\n",
    "    print(f\"\\n{key}: {len(paths)} files\")\n",
    "    for p in paths:\n",
    "        print(f\"  - {p.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "파일: TS_01. 민사법_001. 판결문.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 76291\n",
      "\n",
      "JSON 파일: /민사법_판결문_10019.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['doc_class', 'doc_id', 'casenames', 'normalized_court', 'casetype', 'sentences', 'announce_date']\n",
      "\n",
      "================================================================================\n",
      "파일: TL_01. 민사법_001. 판결문_0001. 질의응답.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 73065\n",
      "\n",
      "JSON 파일: /민사법_판결문_질의응답_10021.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['info', 'taskinfo']\n",
      "\n",
      "================================================================================\n",
      "파일: TL_01. 민사법_001. 판결문_0002. 요약.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 3228\n",
      "\n",
      "JSON 파일: /민사법_판결문_요약_91299.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['info', 'taskinfo']\n",
      "\n",
      "================================================================================\n",
      "파일: TS_01. 민사법_002. 법령.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 12\n",
      "\n",
      "JSON 파일: /민사법_법령_7.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['statute_name', 'effective_date', 'proclamation_date', 'statute_type', 'statute_abbrv', 'statute_category', 'sentences', 'data_class']\n",
      "\n",
      "================================================================================\n",
      "파일: TL_01. 민사법_002. 법령_0001. 질의응답.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 12\n",
      "\n",
      "JSON 파일: /민사법_법령_질의응답_4.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['info', 'taskinfo']\n",
      "\n",
      "================================================================================\n",
      "파일: TS_01. 민사법_003. 심결례.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 2510\n",
      "\n",
      "JSON 파일: /민사법_심결례_1002.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['doc_class', 'document_type', 'doc_id', 'decision_date', 'result', 'sentences']\n",
      "\n",
      "================================================================================\n",
      "파일: TL_01. 민사법_003. 심결례_0001. 질의응답.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 2289\n",
      "\n",
      "JSON 파일: /민사법_심결례_질의응답_1019.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['info', 'taskinfo']\n",
      "\n",
      "================================================================================\n",
      "파일: TS_01. 민사법_004. 유권해석.zip\n",
      "================================================================================\n",
      "JSON 파일 수: 410\n",
      "\n",
      "JSON 파일: /민사법_유권해석_109.json\n",
      "타입: <class 'dict'>\n",
      "Keys: ['doc_class', 'doc_id', 'response_date', 'response_institute', 'sentences', 'title']\n"
     ]
    }
   ],
   "source": [
    "# 각 타입별 샘플 JSON 구조 확인\n",
    "def examine_zip_structure(zpath, max_items=2):\n",
    "    \"\"\"ZIP 파일 내 JSON 구조를 출력\"\"\"\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"파일: {zpath.name}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    with zipfile.ZipFile(zpath, 'r') as zf:\n",
    "        json_files = [f for f in zf.namelist() if f.endswith('.json')]\n",
    "        print(f\"JSON 파일 수: {len(json_files)}\")\n",
    "        \n",
    "        for jf in json_files[:1]:  # 첫 번째 JSON만\n",
    "            with zf.open(jf) as f:\n",
    "                data = json.load(f)\n",
    "            \n",
    "            print(f\"\\nJSON 파일: {jf}\")\n",
    "            print(f\"타입: {type(data)}\")\n",
    "            \n",
    "            if isinstance(data, list):\n",
    "                print(f\"리스트 길이: {len(data)}\")\n",
    "                for i, item in enumerate(data[:max_items]):\n",
    "                    print(f\"\\n--- 항목 {i} ---\")\n",
    "                    if isinstance(item, dict):\n",
    "                        print(f\"Keys: {list(item.keys())}\")\n",
    "                        # 중요 필드만 출력\n",
    "                        for key in list(item.keys())[:8]:\n",
    "                            val = item[key]\n",
    "                            if isinstance(val, str):\n",
    "                                print(f\"  {key}: {val[:100]}\")\n",
    "                            elif isinstance(val, (list, dict)):\n",
    "                                print(f\"  {key}: {type(val).__name__} (len={len(val) if hasattr(val, '__len__') else '?'})\")\n",
    "                            else:\n",
    "                                print(f\"  {key}: {val}\")\n",
    "            elif isinstance(data, dict):\n",
    "                print(f\"Keys: {list(data.keys())}\")\n",
    "\n",
    "# 대표 샘플 검사\n",
    "sample_types = [\n",
    "    (\"train_precedent_source\", \"판결문 원천\"),\n",
    "    (\"train_precedent_qa\", \"판결문 QA\"),\n",
    "    (\"train_precedent_summary\", \"판결문 요약\"),\n",
    "    (\"train_statute_source\", \"법령 원천\"),\n",
    "    (\"train_statute_qa\", \"법령 QA\"),\n",
    "    (\"train_trial_decision_source\", \"심결례 원천\"),\n",
    "    (\"train_trial_decision_qa\", \"심결례 QA\"),\n",
    "    (\"train_authoritative_interpretation_source\", \"유권해석 원천\"),\n",
    "]\n",
    "\n",
    "for key, desc in sample_types:\n",
    "    if key in zip_by_type and zip_by_type[key]:\n",
    "        examine_zip_structure(zip_by_type[key][0], max_items=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb7dc765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "타입별 데이터셋 빌더\n",
      "================================================================================\n",
      "ZIP 파일 로딩 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing ZIPs: 100%|██████████| 22/22 [01:23<00:00,  3.82s/it]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "statute_source 데이터셋 생성 중...\n",
      "  train: 12 rows, 17 columns\n",
      "  validation: 2 rows, 17 columns\n",
      "\n",
      "trial_decision_source 데이터셋 생성 중...\n",
      "  train: 2,510 rows, 15 columns\n",
      "  validation: 406 rows, 15 columns\n",
      "\n",
      "precedent_source 데이터셋 생성 중...\n",
      "  train: 2,510 rows, 15 columns\n",
      "  validation: 406 rows, 15 columns\n",
      "\n",
      "precedent_source 데이터셋 생성 중...\n",
      "  train: 76,291 rows, 16 columns\n",
      "  train: 76,291 rows, 16 columns\n",
      "  validation: 9,527 rows, 16 columns\n",
      "\n",
      "interpretation_source 데이터셋 생성 중...\n",
      "  train: 410 rows, 15 columns\n",
      "  validation: 66 rows, 15 columns\n",
      "\n",
      "precedent_qa 데이터셋 생성 중...\n",
      "  validation: 9,527 rows, 16 columns\n",
      "\n",
      "interpretation_source 데이터셋 생성 중...\n",
      "  train: 410 rows, 15 columns\n",
      "  validation: 66 rows, 15 columns\n",
      "\n",
      "precedent_qa 데이터셋 생성 중...\n",
      "  train: 73,065 rows, 15 columns\n",
      "  validation: 9,135 rows, 15 columns\n",
      "\n",
      "precedent_summary 데이터셋 생성 중...\n",
      "  train: 3,228 rows, 14 columns\n",
      "  validation: 392 rows, 14 columns\n",
      "\n",
      "statute_qa 데이터셋 생성 중...\n",
      "  train: 12 rows, 13 columns\n",
      "  validation: 2 rows, 13 columns\n",
      "\n",
      "trial_decision_qa 데이터셋 생성 중...\n",
      "  train: 2,289 rows, 14 columns\n",
      "  validation: 279 rows, 14 columns\n",
      "\n",
      "trial_decision_summary 데이터셋 생성 중...\n",
      "  train: 73,065 rows, 15 columns\n",
      "  validation: 9,135 rows, 15 columns\n",
      "\n",
      "precedent_summary 데이터셋 생성 중...\n",
      "  train: 3,228 rows, 14 columns\n",
      "  validation: 392 rows, 14 columns\n",
      "\n",
      "statute_qa 데이터셋 생성 중...\n",
      "  train: 12 rows, 13 columns\n",
      "  validation: 2 rows, 13 columns\n",
      "\n",
      "trial_decision_qa 데이터셋 생성 중...\n",
      "  train: 2,289 rows, 14 columns\n",
      "  validation: 279 rows, 14 columns\n",
      "\n",
      "trial_decision_summary 데이터셋 생성 중...\n",
      "  train: 1,100 rows, 7 columns\n",
      "  validation: 140 rows, 7 columns\n",
      "\n",
      "interpretation_qa 데이터셋 생성 중...\n",
      "  train: 258 rows, 7 columns\n",
      "  validation: 38 rows, 7 columns\n",
      "\n",
      "interpretation_summary 데이터셋 생성 중...\n",
      "  train: 152 rows, 7 columns\n",
      "  validation: 28 rows, 7 columns\n",
      "\n",
      "================================================================================\n",
      "빌드 완료!\n",
      "================================================================================\n",
      "\n",
      "statute_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'proclamation_date', 'statute_type', 'statute_abbrv', 'statute_category', 'data_class', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 12\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'proclamation_date', 'statute_type', 'statute_abbrv', 'statute_category', 'data_class', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n",
      "\n",
      "trial_decision_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_class', 'document_type', 'doc_id', 'decision_date', 'result', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2510\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_class', 'document_type', 'doc_id', 'decision_date', 'result', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 406\n",
      "    })\n",
      "})\n",
      "\n",
      "precedent_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 76291\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 9527\n",
      "    })\n",
      "})\n",
      "\n",
      "interpretation_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'response_date', 'response_institute', 'title', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 410\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'response_date', 'response_institute', 'title', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 66\n",
      "    })\n",
      "})\n",
      "\n",
      "precedent_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 73065\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 9135\n",
      "    })\n",
      "})\n",
      "\n",
      "precedent_summary:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'summaries', 'summary_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 3228\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'summaries', 'summary_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 392\n",
      "    })\n",
      "})\n",
      "\n",
      "statute_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'statute_type', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 12\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'statute_type', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n",
      "\n",
      "trial_decision_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_id', 'document_type', 'decision_date', 'result', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2289\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_id', 'document_type', 'decision_date', 'result', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 279\n",
      "    })\n",
      "})\n",
      "\n",
      "trial_decision_summary:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 1100\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 140\n",
      "    })\n",
      "})\n",
      "\n",
      "interpretation_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 258\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 38\n",
      "    })\n",
      "})\n",
      "\n",
      "interpretation_summary:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 152\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 28\n",
      "    })\n",
      "})\n",
      "  train: 1,100 rows, 7 columns\n",
      "  validation: 140 rows, 7 columns\n",
      "\n",
      "interpretation_qa 데이터셋 생성 중...\n",
      "  train: 258 rows, 7 columns\n",
      "  validation: 38 rows, 7 columns\n",
      "\n",
      "interpretation_summary 데이터셋 생성 중...\n",
      "  train: 152 rows, 7 columns\n",
      "  validation: 28 rows, 7 columns\n",
      "\n",
      "================================================================================\n",
      "빌드 완료!\n",
      "================================================================================\n",
      "\n",
      "statute_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'proclamation_date', 'statute_type', 'statute_abbrv', 'statute_category', 'data_class', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 12\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'proclamation_date', 'statute_type', 'statute_abbrv', 'statute_category', 'data_class', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n",
      "\n",
      "trial_decision_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_class', 'document_type', 'doc_id', 'decision_date', 'result', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2510\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_class', 'document_type', 'doc_id', 'decision_date', 'result', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 406\n",
      "    })\n",
      "})\n",
      "\n",
      "precedent_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 76291\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 9527\n",
      "    })\n",
      "})\n",
      "\n",
      "interpretation_source:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'response_date', 'response_institute', 'title', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 410\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_class', 'doc_id', 'response_date', 'response_institute', 'title', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 66\n",
      "    })\n",
      "})\n",
      "\n",
      "precedent_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 73065\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 9135\n",
      "    })\n",
      "})\n",
      "\n",
      "precedent_summary:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'summaries', 'summary_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 3228\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'summaries', 'summary_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 392\n",
      "    })\n",
      "})\n",
      "\n",
      "statute_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'statute_type', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 12\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['statute_name', 'effective_date', 'statute_type', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2\n",
      "    })\n",
      "})\n",
      "\n",
      "trial_decision_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['doc_id', 'document_type', 'decision_date', 'result', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 2289\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['doc_id', 'document_type', 'decision_date', 'result', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 279\n",
      "    })\n",
      "})\n",
      "\n",
      "trial_decision_summary:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 1100\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 140\n",
      "    })\n",
      "})\n",
      "\n",
      "interpretation_qa:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 258\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 38\n",
      "    })\n",
      "})\n",
      "\n",
      "interpretation_summary:\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 152\n",
      "    })\n",
      "    validation: Dataset({\n",
      "        features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
      "        num_rows: 28\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "타입별 데이터셋 빌더\n",
    "각 문서 타입(판결문, 법령, 심결례, 유권해석)과 태스크(원천/QA/요약)별로 별도 데이터셋 생성\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import zipfile\n",
    "import json\n",
    "from datasets import Dataset, DatasetDict\n",
    "from tqdm.auto import tqdm\n",
    "from typing import Any, Dict, List\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class TypedDatasetBuilder:\n",
    "    \"\"\"문서 타입별 데이터셋 빌더\"\"\"\n",
    "    \n",
    "    def __init__(self, base_dir: str):\n",
    "        self.base_dir = Path(base_dir)\n",
    "        self.zip_files = list(self.base_dir.rglob(\"*.zip\"))\n",
    "        self.datasets_by_type = defaultdict(lambda: {\"train\": [], \"validation\": []})\n",
    "    \n",
    "    def classify_zip(self, zpath: Path) -> tuple:\n",
    "        \"\"\"ZIP 파일명으로 분류\"\"\"\n",
    "        name = zpath.name\n",
    "        \n",
    "        # 데이터 타입\n",
    "        if \"판결문\" in name:\n",
    "            data_type = \"precedent\"\n",
    "        elif \"법령\" in name:\n",
    "            data_type = \"statute\"\n",
    "        elif \"심결례\" in name:\n",
    "            data_type = \"trial_decision\"\n",
    "        elif \"유권해석\" in name:\n",
    "            data_type = \"interpretation\"\n",
    "        else:\n",
    "            data_type = \"unknown\"\n",
    "        \n",
    "        # 태스크 타입\n",
    "        if \"질의응답\" in name:\n",
    "            task_type = \"qa\"\n",
    "        elif \"요약\" in name:\n",
    "            task_type = \"summary\"\n",
    "        else:\n",
    "            task_type = \"source\"\n",
    "        \n",
    "        # Split\n",
    "        split = \"train\" if (\"TL_\" in name or \"TS_\" in name) else \"validation\"\n",
    "        \n",
    "        return split, data_type, task_type\n",
    "    \n",
    "    def process_precedent_source(self, item: Dict) -> Dict:\n",
    "        \"\"\"판결문 원천 데이터 처리\"\"\"\n",
    "        sentences = item.get(\"sentences\", [])\n",
    "        text = \" \".join([s.get(\"text\", \"\") for s in sentences if isinstance(s, dict)])\n",
    "        \n",
    "        return {\n",
    "            \"doc_class\": item.get(\"doc_class\"),\n",
    "            \"doc_id\": item.get(\"doc_id\"),\n",
    "            \"casenames\": item.get(\"casenames\"),\n",
    "            \"normalized_court\": item.get(\"normalized_court\"),\n",
    "            \"casetype\": item.get(\"casetype\"),\n",
    "            \"announce_date\": item.get(\"announce_date\"),\n",
    "            \"text\": text,\n",
    "            \"sentences\": json.dumps(sentences, ensure_ascii=False),\n",
    "            \"char_len\": len(text),\n",
    "            \"word_len\": len(text.split()),\n",
    "        }\n",
    "    \n",
    "    def process_precedent_qa(self, item: Dict) -> Dict:\n",
    "        \"\"\"판결문 QA 데이터 처리\"\"\"\n",
    "        info = item.get(\"info\", {})\n",
    "        taskinfo = item.get(\"taskinfo\", [])\n",
    "        \n",
    "        questions = []\n",
    "        answers = []\n",
    "        for task in taskinfo:\n",
    "            if isinstance(task, dict):\n",
    "                q = task.get(\"question\")\n",
    "                a = task.get(\"answer\")\n",
    "                if q: questions.append(q)\n",
    "                if a: answers.append(a)\n",
    "        \n",
    "        return {\n",
    "            \"doc_id\": info.get(\"doc_id\"),\n",
    "            \"casenames\": info.get(\"casenames\"),\n",
    "            \"normalized_court\": info.get(\"normalized_court\"),\n",
    "            \"casetype\": info.get(\"casetype\"),\n",
    "            \"announce_date\": info.get(\"announce_date\"),\n",
    "            \"questions\": questions,\n",
    "            \"answers\": answers,\n",
    "            \"qa_count\": len(questions),\n",
    "            \"info_json\": json.dumps(info, ensure_ascii=False),\n",
    "        }\n",
    "    \n",
    "    def process_precedent_summary(self, item: Dict) -> Dict:\n",
    "        \"\"\"판결문 요약 데이터 처리\"\"\"\n",
    "        info = item.get(\"info\", {})\n",
    "        taskinfo = item.get(\"taskinfo\", [])\n",
    "        \n",
    "        summaries = []\n",
    "        for task in taskinfo:\n",
    "            if isinstance(task, dict):\n",
    "                summ = task.get(\"summary\")\n",
    "                if summ: summaries.append(summ)\n",
    "        \n",
    "        return {\n",
    "            \"doc_id\": info.get(\"doc_id\"),\n",
    "            \"casenames\": info.get(\"casenames\"),\n",
    "            \"normalized_court\": info.get(\"normalized_court\"),\n",
    "            \"casetype\": info.get(\"casetype\"),\n",
    "            \"announce_date\": info.get(\"announce_date\"),\n",
    "            \"summaries\": summaries,\n",
    "            \"summary_count\": len(summaries),\n",
    "            \"info_json\": json.dumps(info, ensure_ascii=False),\n",
    "        }\n",
    "    \n",
    "    def process_statute_source(self, item: Dict) -> Dict:\n",
    "        \"\"\"법령 원천 데이터 처리\"\"\"\n",
    "        sentences = item.get(\"sentences\", [])\n",
    "        text = \" \".join([s.get(\"text\", \"\") for s in sentences if isinstance(s, dict)])\n",
    "        \n",
    "        return {\n",
    "            \"statute_name\": item.get(\"statute_name\"),\n",
    "            \"effective_date\": item.get(\"effective_date\"),\n",
    "            \"proclamation_date\": item.get(\"proclamation_date\"),\n",
    "            \"statute_type\": item.get(\"statute_type\"),\n",
    "            \"statute_abbrv\": item.get(\"statute_abbrv\"),\n",
    "            \"statute_category\": item.get(\"statute_category\"),\n",
    "            \"data_class\": item.get(\"data_class\"),\n",
    "            \"text\": text,\n",
    "            \"sentences\": json.dumps(sentences, ensure_ascii=False),\n",
    "            \"char_len\": len(text),\n",
    "            \"word_len\": len(text.split()),\n",
    "        }\n",
    "    \n",
    "    def process_statute_qa(self, item: Dict) -> Dict:\n",
    "        \"\"\"법령 QA 데이터 처리\"\"\"\n",
    "        info = item.get(\"info\", {})\n",
    "        taskinfo = item.get(\"taskinfo\", [])\n",
    "        \n",
    "        questions = []\n",
    "        answers = []\n",
    "        for task in taskinfo:\n",
    "            if isinstance(task, dict):\n",
    "                q = task.get(\"question\")\n",
    "                a = task.get(\"answer\")\n",
    "                if q: questions.append(q)\n",
    "                if a: answers.append(a)\n",
    "        \n",
    "        return {\n",
    "            \"statute_name\": info.get(\"statute_name\"),\n",
    "            \"effective_date\": info.get(\"effective_date\"),\n",
    "            \"statute_type\": info.get(\"statute_type\"),\n",
    "            \"questions\": questions,\n",
    "            \"answers\": answers,\n",
    "            \"qa_count\": len(questions),\n",
    "            \"info_json\": json.dumps(info, ensure_ascii=False),\n",
    "        }\n",
    "    \n",
    "    def process_trial_decision_source(self, item: Dict) -> Dict:\n",
    "        \"\"\"심결례 원천 데이터 처리\"\"\"\n",
    "        sentences = item.get(\"sentences\", [])\n",
    "        text = \" \".join([s.get(\"text\", \"\") for s in sentences if isinstance(s, dict)])\n",
    "        \n",
    "        return {\n",
    "            \"doc_class\": item.get(\"doc_class\"),\n",
    "            \"document_type\": item.get(\"document_type\"),\n",
    "            \"doc_id\": item.get(\"doc_id\"),\n",
    "            \"decision_date\": item.get(\"decision_date\"),\n",
    "            \"result\": item.get(\"result\"),\n",
    "            \"text\": text,\n",
    "            \"sentences\": json.dumps(sentences, ensure_ascii=False),\n",
    "            \"char_len\": len(text),\n",
    "            \"word_len\": len(text.split()),\n",
    "        }\n",
    "    \n",
    "    def process_trial_decision_qa(self, item: Dict) -> Dict:\n",
    "        \"\"\"심결례 QA 데이터 처리\"\"\"\n",
    "        info = item.get(\"info\", {})\n",
    "        taskinfo = item.get(\"taskinfo\", [])\n",
    "        \n",
    "        questions = []\n",
    "        answers = []\n",
    "        for task in taskinfo:\n",
    "            if isinstance(task, dict):\n",
    "                q = task.get(\"question\")\n",
    "                a = task.get(\"answer\")\n",
    "                if q: questions.append(q)\n",
    "                if a: answers.append(a)\n",
    "        \n",
    "        return {\n",
    "            \"doc_id\": info.get(\"doc_id\"),\n",
    "            \"document_type\": info.get(\"document_type\"),\n",
    "            \"decision_date\": info.get(\"decision_date\"),\n",
    "            \"result\": info.get(\"result\"),\n",
    "            \"questions\": questions,\n",
    "            \"answers\": answers,\n",
    "            \"qa_count\": len(questions),\n",
    "            \"info_json\": json.dumps(info, ensure_ascii=False),\n",
    "        }\n",
    "    \n",
    "    def process_interpretation_source(self, item: Dict) -> Dict:\n",
    "        \"\"\"유권해석 원천 데이터 처리\"\"\"\n",
    "        sentences = item.get(\"sentences\", [])\n",
    "        text = \" \".join([s.get(\"text\", \"\") for s in sentences if isinstance(s, dict)])\n",
    "        \n",
    "        return {\n",
    "            \"doc_class\": item.get(\"doc_class\"),\n",
    "            \"doc_id\": item.get(\"doc_id\"),\n",
    "            \"response_date\": item.get(\"response_date\"),\n",
    "            \"response_institute\": item.get(\"response_institute\"),\n",
    "            \"title\": item.get(\"title\"),\n",
    "            \"text\": text,\n",
    "            \"sentences\": json.dumps(sentences, ensure_ascii=False),\n",
    "            \"char_len\": len(text),\n",
    "            \"word_len\": len(text.split()),\n",
    "        }\n",
    "    \n",
    "    def process_item(self, item: Dict, data_type: str, task_type: str, \n",
    "                    source_zip: str, source_json: str) -> Dict:\n",
    "        \"\"\"항목 처리 라우터\"\"\"\n",
    "        # 타입별 처리 함수 매핑\n",
    "        processors = {\n",
    "            (\"precedent\", \"source\"): self.process_precedent_source,\n",
    "            (\"precedent\", \"qa\"): self.process_precedent_qa,\n",
    "            (\"precedent\", \"summary\"): self.process_precedent_summary,\n",
    "            (\"statute\", \"source\"): self.process_statute_source,\n",
    "            (\"statute\", \"qa\"): self.process_statute_qa,\n",
    "            (\"trial_decision\", \"source\"): self.process_trial_decision_source,\n",
    "            (\"trial_decision\", \"qa\"): self.process_trial_decision_qa,\n",
    "            (\"interpretation\", \"source\"): self.process_interpretation_source,\n",
    "        }\n",
    "        \n",
    "        processor = processors.get((data_type, task_type))\n",
    "        if processor:\n",
    "            record = processor(item)\n",
    "        else:\n",
    "            # 처리 함수가 없으면 원본 JSON 보존\n",
    "            record = {\"raw_json\": json.dumps(item, ensure_ascii=False)}\n",
    "        \n",
    "        # 메타데이터 추가\n",
    "        record.update({\n",
    "            \"_source_zip\": source_zip,\n",
    "            \"_source_json\": source_json,\n",
    "            \"_data_type\": data_type,\n",
    "            \"_task_type\": task_type,\n",
    "        })\n",
    "        \n",
    "        return record\n",
    "    \n",
    "    def load_zip(self, zpath: Path):\n",
    "        \"\"\"ZIP 파일 로드\"\"\"\n",
    "        split, data_type, task_type = self.classify_zip(zpath)\n",
    "        dataset_key = f\"{data_type}_{task_type}\"\n",
    "        \n",
    "        with zipfile.ZipFile(zpath, 'r') as zf:\n",
    "            json_files = [f for f in zf.namelist() if f.endswith('.json')]\n",
    "            \n",
    "            for jf in json_files:\n",
    "                with zf.open(jf) as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # 단일 dict나 list 처리\n",
    "                items = [data] if isinstance(data, dict) else data\n",
    "                \n",
    "                for item in items:\n",
    "                    if isinstance(item, dict):\n",
    "                        record = self.process_item(\n",
    "                            item, data_type, task_type,\n",
    "                            zpath.name, jf\n",
    "                        )\n",
    "                        self.datasets_by_type[dataset_key][split].append(record)\n",
    "    \n",
    "    def build(self) -> Dict[str, DatasetDict]:\n",
    "        \"\"\"전체 빌드\"\"\"\n",
    "        print(\"ZIP 파일 로딩 중...\")\n",
    "        for zpath in tqdm(self.zip_files, desc=\"Processing ZIPs\"):\n",
    "            try:\n",
    "                self.load_zip(zpath)\n",
    "            except Exception as e:\n",
    "                print(f\"✗ {zpath.name}: {e}\")\n",
    "        \n",
    "        # 각 타입별 DatasetDict 생성\n",
    "        result = {}\n",
    "        \n",
    "        for dataset_key, splits_data in self.datasets_by_type.items():\n",
    "            print(f\"\\n{dataset_key} 데이터셋 생성 중...\")\n",
    "            \n",
    "            dataset_dict = {}\n",
    "            for split, records in splits_data.items():\n",
    "                if not records:\n",
    "                    continue\n",
    "                \n",
    "                ds = Dataset.from_list(records)\n",
    "                ds = ds.add_column(\"_row_id\", [f\"{split}-{i:07d}\" for i in range(len(ds))])\n",
    "                ds = ds.add_column(\"_split\", [split] * len(ds))\n",
    "                \n",
    "                dataset_dict[split] = ds\n",
    "                print(f\"  {split}: {len(ds):,} rows, {len(ds.column_names)} columns\")\n",
    "            \n",
    "            if dataset_dict:\n",
    "                result[dataset_key] = DatasetDict(dataset_dict)\n",
    "        \n",
    "        return result\n",
    "\n",
    "\n",
    "# 빌드 실행\n",
    "print(\"=\"*80)\n",
    "print(\"타입별 데이터셋 빌더\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "builder = TypedDatasetBuilder(BASE_DIR)\n",
    "typed_datasets = builder.build()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"빌드 완료!\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, ds_dict in typed_datasets.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(ds_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1cabc2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터셋 수: 11\n",
      "데이터셋 키들: ['statute_source', 'trial_decision_source', 'precedent_source', 'interpretation_source', 'precedent_qa', 'precedent_summary', 'statute_qa', 'trial_decision_qa', 'trial_decision_summary', 'interpretation_qa', 'interpretation_summary']\n",
      "\n",
      "statute_source:\n",
      "  - train: 12 rows\n",
      "  - validation: 2 rows\n",
      "\n",
      "trial_decision_source:\n",
      "  - train: 2510 rows\n",
      "  - validation: 406 rows\n",
      "\n",
      "precedent_source:\n",
      "  - train: 76291 rows\n",
      "  - validation: 9527 rows\n",
      "\n",
      "interpretation_source:\n",
      "  - train: 410 rows\n",
      "  - validation: 66 rows\n",
      "\n",
      "precedent_qa:\n",
      "  - train: 73065 rows\n",
      "  - validation: 9135 rows\n",
      "\n",
      "precedent_summary:\n",
      "  - train: 3228 rows\n",
      "  - validation: 392 rows\n",
      "\n",
      "statute_qa:\n",
      "  - train: 12 rows\n",
      "  - validation: 2 rows\n",
      "\n",
      "trial_decision_qa:\n",
      "  - train: 2289 rows\n",
      "  - validation: 279 rows\n",
      "\n",
      "trial_decision_summary:\n",
      "  - train: 1100 rows\n",
      "  - validation: 140 rows\n",
      "\n",
      "interpretation_qa:\n",
      "  - train: 258 rows\n",
      "  - validation: 38 rows\n",
      "\n",
      "interpretation_summary:\n",
      "  - train: 152 rows\n",
      "  - validation: 28 rows\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# typed_datasets가 이미 딕셔너리 형태라고 가정\n",
    "# 각 키의 값이 DatasetDict인 경우\n",
    "\n",
    "# 방법 1: typed_datasets가 일반 딕셔너리인 경우\n",
    "if isinstance(typed_datasets, dict) and not isinstance(typed_datasets, DatasetDict):\n",
    "    typed_datasets = DatasetDict(typed_datasets)\n",
    "\n",
    "# 방법 2: 중첩된 구조인 경우 (각 키마다 train/validation이 있는 경우)\n",
    "# 이미 DatasetDict 형태이므로 변환 불필요\n",
    "# typed_datasets의 각 키는 이미 DatasetDict입니다\n",
    "\n",
    "# 사용 예시:\n",
    "print(f\"총 데이터셋 수: {len(typed_datasets)}\")\n",
    "print(f\"데이터셋 키들: {list(typed_datasets.keys())}\")\n",
    "\n",
    "# 각 데이터셋 확인\n",
    "for key, dataset_dict in typed_datasets.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  - train: {len(dataset_dict['train'])} rows\")\n",
    "    print(f\"  - validation: {len(dataset_dict['validation'])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c788cace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    statute_source: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['statute_name', 'effective_date', 'proclamation_date', 'statute_type', 'statute_abbrv', 'statute_category', 'data_class', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 12\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['statute_name', 'effective_date', 'proclamation_date', 'statute_type', 'statute_abbrv', 'statute_category', 'data_class', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 2\n",
       "        })\n",
       "    })\n",
       "    trial_decision_source: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['doc_class', 'document_type', 'doc_id', 'decision_date', 'result', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 2510\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['doc_class', 'document_type', 'doc_id', 'decision_date', 'result', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 406\n",
       "        })\n",
       "    })\n",
       "    precedent_source: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['doc_class', 'doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 76291\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['doc_class', 'doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 9527\n",
       "        })\n",
       "    })\n",
       "    interpretation_source: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['doc_class', 'doc_id', 'response_date', 'response_institute', 'title', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 410\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['doc_class', 'doc_id', 'response_date', 'response_institute', 'title', 'text', 'sentences', 'char_len', 'word_len', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 66\n",
       "        })\n",
       "    })\n",
       "    precedent_qa: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 73065\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 9135\n",
       "        })\n",
       "    })\n",
       "    precedent_summary: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'summaries', 'summary_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 3228\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['doc_id', 'casenames', 'normalized_court', 'casetype', 'announce_date', 'summaries', 'summary_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 392\n",
       "        })\n",
       "    })\n",
       "    statute_qa: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['statute_name', 'effective_date', 'statute_type', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 12\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['statute_name', 'effective_date', 'statute_type', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 2\n",
       "        })\n",
       "    })\n",
       "    trial_decision_qa: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['doc_id', 'document_type', 'decision_date', 'result', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 2289\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['doc_id', 'document_type', 'decision_date', 'result', 'questions', 'answers', 'qa_count', 'info_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 279\n",
       "        })\n",
       "    })\n",
       "    trial_decision_summary: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 1100\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 140\n",
       "        })\n",
       "    })\n",
       "    interpretation_qa: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 258\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 38\n",
       "        })\n",
       "    })\n",
       "    interpretation_summary: DatasetDict({\n",
       "        train: Dataset({\n",
       "            features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 152\n",
       "        })\n",
       "        validation: Dataset({\n",
       "            features: ['raw_json', '_source_zip', '_source_json', '_data_type', '_task_type', '_row_id', '_split'],\n",
       "            num_rows: 28\n",
       "        })\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typed_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c653c3c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "데이터셋 샘플 확인\n",
      "================================================================================\n",
      "\n",
      "================================================================================\n",
      "데이터셋: statute_source\n",
      "================================================================================\n",
      "\n",
      "[train] 12 rows\n",
      "Columns: statute_name, effective_date, proclamation_date, statute_type, statute_abbrv, statute_category, data_class, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type\n",
      "         ... and 2 more\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: statute\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_법령_7.json\n",
      "  _source_zip: TS_01. 민사법_002. 법령.zip\n",
      "  _split: train\n",
      "  _task_type: source\n",
      "  char_len: 0\n",
      "  data_class: 2\n",
      "  effective_date: 2024-08-01 00:00:00\n",
      "  proclamation_date: 2023-08-08 00:00:00\n",
      "  sentences: [\"제1조(목적)\\n\", \"이 법은 민사소송 등에서 전자문서 이용에 대한 기본 원칙과 절차를 규정함으로써 민사소송 등의 정보화를 촉진하고 신속성, 투명성을 높여 국민의 권리 실현에...\n",
      "  statute_abbrv: 민소전자문서법\n",
      "  statute_category: 민사법\n",
      "  statute_name: 민사소송등에서의전자문서이용등에관한법률\n",
      "  statute_type: 법률\n",
      "  text: \n",
      "  word_len: 0\n",
      "\n",
      "[validation] 2 rows\n",
      "Columns: statute_name, effective_date, proclamation_date, statute_type, statute_abbrv, statute_category, data_class, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type\n",
      "         ... and 2 more\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: statute\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_법령_11.json\n",
      "  _source_zip: VS_01. 민사법_002. 법령.zip\n",
      "  _split: validation\n",
      "  _task_type: source\n",
      "  char_len: 0\n",
      "  data_class: 2\n",
      "  effective_date: 2023-10-19 00:00:00\n",
      "  proclamation_date: 2023-04-18 00:00:00\n",
      "  sentences: [\"제1조(민사소송의 이상과 신의성실의 원칙)\\n\", \"①법원은 소송절차가 공정하고 신속하며 경제적으로 진행되도록 노력하여야 한다.\\n\", \"②당사자와 소송관계인은 신의에 따라 성...\n",
      "  statute_abbrv: 민사소송법\n",
      "  statute_category: 민사법\n",
      "  statute_name: 민사소송법\n",
      "  statute_type: 법률\n",
      "  text: \n",
      "  word_len: 0\n",
      "\n",
      "================================================================================\n",
      "데이터셋: trial_decision_source\n",
      "================================================================================\n",
      "\n",
      "[train] 2,510 rows\n",
      "Columns: doc_class, document_type, doc_id, decision_date, result, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: trial_decision\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_심결례_1002.json\n",
      "  _source_zip: TS_01. 민사법_003. 심결례.zip\n",
      "  _split: train\n",
      "  _task_type: source\n",
      "  char_len: 0\n",
      "  decision_date: 2023.04.04\n",
      "  doc_class: 3\n",
      "  doc_id: 22-진정-0477900\n",
      "  document_type: 국가인권위원회\n",
      "  result: None\n",
      "  sentences: [\"진정인은 장교로 복무하는 중이고, 202×.\\n\", \"×.경 전역 예정이다\\n\", \"진정인은사이버 대학교(4년제)를 다니면서 공군 조종분야 가산복무 지원금 지급대상자 중 '학사...\n",
      "  text: \n",
      "  word_len: 0\n",
      "\n",
      "[validation] 406 rows\n",
      "Columns: doc_class, document_type, doc_id, decision_date, result, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: trial_decision\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_심결례_1005.json\n",
      "  _source_zip: VS_01. 민사법_003. 심결례.zip\n",
      "  _split: validation\n",
      "  _task_type: source\n",
      "  char_len: 0\n",
      "  decision_date: 2012.07.10\n",
      "  doc_class: 3\n",
      "  doc_id: 12-진정-0189800\n",
      "  document_type: 국가인권위원회\n",
      "  result: None\n",
      "  sentences: [\"가.2012. 3. 7. 오후 5시30분경 O○출입국관리사무소 소속 공무원들이 진정인이 운영하는 사업장(OO기업, · 소재)에 사전 고지 없이진입하여 단속한 것은 위법한 인권침...\n",
      "  text: \n",
      "  word_len: 0\n",
      "\n",
      "================================================================================\n",
      "데이터셋: precedent_source\n",
      "================================================================================\n",
      "\n",
      "[train] 76,291 rows\n",
      "Columns: doc_class, doc_id, casenames, normalized_court, casetype, announce_date, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type, _row_id\n",
      "         ... and 1 more\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: precedent\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_판결문_10019.json\n",
      "  _source_zip: TS_01. 민사법_001. 판결문.zip\n",
      "  _split: train\n",
      "  _task_type: source\n",
      "  announce_date: 2017-10-31T09:00:00.000+09:00\n",
      "  casenames: 손해배상(기)\n",
      "  casetype: civil\n",
      "  char_len: 0\n",
      "  doc_class: 1\n",
      "  doc_id: 대구지방법원포항지원-2016가단105501\n",
      "  normalized_court: 대구지방법원포항지원\n",
      "  sentences: [\"1. 원고의 피고들에 대한 청구를 모두 기각한다.\", \"2. 소송비용은 원고가 부담한다.\", \"피고들은 각자 원고에게 184,680,000원 및 이에 대하여 이 사건 소장송달일...\n",
      "  text: \n",
      "  word_len: 0\n",
      "\n",
      "[validation] 9,527 rows\n",
      "Columns: doc_class, doc_id, casenames, normalized_court, casetype, announce_date, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type, _row_id\n",
      "         ... and 1 more\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: precedent\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_판결문_1044.json\n",
      "  _source_zip: VS_01. 민사법_001. 판결문.zip\n",
      "  _split: validation\n",
      "  _task_type: source\n",
      "  announce_date: 2016-12-20T09:00:00.000+09:00\n",
      "  casenames: 대여금반환\n",
      "  casetype: civil\n",
      "  char_len: 0\n",
      "  doc_class: 1\n",
      "  doc_id: 창원지방법원-2016나53873\n",
      "  normalized_court: 창원지방법원\n",
      "  sentences: [\"특별한 사정이 없는 한 피고는 D와 연대하여 원고에게 대여금 6,300만 원 중 원고가 구하는 5,300만 원 및 이에 대하여 변제기 이후로서 원고가 구하는 2000. 4. 7...\n",
      "  text: \n",
      "  word_len: 0\n",
      "\n",
      "================================================================================\n",
      "데이터셋: interpretation_source\n",
      "================================================================================\n",
      "\n",
      "[train] 410 rows\n",
      "Columns: doc_class, doc_id, response_date, response_institute, title, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: interpretation\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_유권해석_109.json\n",
      "  _source_zip: TS_01. 민사법_004. 유권해석.zip\n",
      "  _split: train\n",
      "  _task_type: source\n",
      "  char_len: 0\n",
      "  doc_class: 4\n",
      "  doc_id: 고용노동부-질의회시-PDF-1e5dce8-퇴직연금복지과-3347\n",
      "  response_date: 2021. 07. 22\n",
      "  response_institute: 고용노동부\n",
      "  sentences: [\"질의\\n\", \"• (상황) 당사의 분할(1개→2개) 예정에 따라 사내근로복지기금 또한 분할이 필요한 상황.\\n\", \"• (질의1) 기금액은 분할되는 종업원 수에 따라 동등하게 ...\n",
      "  text: \n",
      "  title: 사내근로복지기금 분할 절차 및 대부금 처리\n",
      "  word_len: 0\n",
      "\n",
      "[validation] 66 rows\n",
      "Columns: doc_class, doc_id, response_date, response_institute, title, text, sentences, char_len, word_len, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: interpretation\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_유권해석_371.json\n",
      "  _source_zip: VS_01. 민사법_004. 유권해석.zip\n",
      "  _split: validation\n",
      "  _task_type: source\n",
      "  char_len: 0\n",
      "  doc_class: 4\n",
      "  doc_id: 고용노동부-질의회시-PDF-0d94d01-퇴직급여보장팀-718\n",
      "  response_date: 2006. 03. 06\n",
      "  response_institute: 고용노동부\n",
      "  sentences: [\"DC의 경우 과거근로기간을 퇴직연금 가입기간으로 하되, 과거근로기간 전체를 일시에 가입기간에 포함시키지 않고 이를 일정단위로나누어 순차적으로 가입기간에 포함시키며, 사용자의 부...\n",
      "  text: \n",
      "  title: DC의 과거근로기간 적립금 납부 방법\n",
      "  word_len: 0\n",
      "\n",
      "================================================================================\n",
      "데이터셋: precedent_qa\n",
      "================================================================================\n",
      "\n",
      "[train] 73,065 rows\n",
      "Columns: doc_id, casenames, normalized_court, casetype, announce_date, questions, answers, qa_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: precedent\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_판결문_질의응답_10021.json\n",
      "  _source_zip: TL_01. 민사법_001. 판결문_0001. 질의응답.zip\n",
      "  _split: train\n",
      "  _task_type: qa\n",
      "  announce_date: 2020-12-08T09:00:00.000+09:00\n",
      "  answers: list[0]\n",
      "  casenames: 손해배상(기)\n",
      "  casetype: civil\n",
      "  doc_id: 대구지방법원포항지원-2020가단2937\n",
      "  info_json: {\"doc_class\": \"1\", \"doc_id\": \"대구지방법원포항지원-2020가단2937\", \"announce_date\": \"2020-12-08T09:00:00.000+09:0...\n",
      "  normalized_court: 대구지방법원 포항지원\n",
      "  qa_count: 0\n",
      "  questions: list[0]\n",
      "\n",
      "[validation] 9,135 rows\n",
      "Columns: doc_id, casenames, normalized_court, casetype, announce_date, questions, answers, qa_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: precedent\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_판결문_질의응답_10188.json\n",
      "  _source_zip: VL_01. 민사법_001. 판결문_0001. 질의응답.zip\n",
      "  _split: validation\n",
      "  _task_type: qa\n",
      "  announce_date: 2013-08-21T09:00:00.000+09:00\n",
      "  answers: list[0]\n",
      "  casenames: 손해배상(기)정산금\n",
      "  casetype: civil\n",
      "  doc_id: 부산지방법원-2011가합781\n",
      "  info_json: {\"doc_class\": \"1\", \"doc_id\": \"부산지방법원-2011가합781\", \"announce_date\": \"2013-08-21T09:00:00.000+09:00\", \"...\n",
      "  normalized_court: 부산지방법원\n",
      "  qa_count: 0\n",
      "  questions: list[0]\n",
      "\n",
      "================================================================================\n",
      "데이터셋: precedent_summary\n",
      "================================================================================\n",
      "\n",
      "[train] 3,228 rows\n",
      "Columns: doc_id, casenames, normalized_court, casetype, announce_date, summaries, summary_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: precedent\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_판결문_요약_91299.json\n",
      "  _source_zip: TL_01. 민사법_001. 판결문_0002. 요약.zip\n",
      "  _split: train\n",
      "  _task_type: summary\n",
      "  announce_date: 2018-10-24T09:00:00.000+09:00\n",
      "  casenames: 대여금\n",
      "  casetype: civil\n",
      "  doc_id: 부산지방법원-2017가합50085\n",
      "  info_json: {\"doc_class\": \"1\", \"doc_id\": \"부산지방법원-2017가합50085\", \"announce_date\": \"2018-10-24T09:00:00.000+09:00\",...\n",
      "  normalized_court: 부산지방법원\n",
      "  summaries: list[0]\n",
      "  summary_count: 0\n",
      "\n",
      "[validation] 392 rows\n",
      "Columns: doc_id, casenames, normalized_court, casetype, announce_date, summaries, summary_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: precedent\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_판결문_요약_91366.json\n",
      "  _source_zip: VL_01. 민사법_001. 판결문_0002. 요약.zip\n",
      "  _split: validation\n",
      "  _task_type: summary\n",
      "  announce_date: 2017-03-15T09:00:00.000+09:00\n",
      "  casenames: 구상금\n",
      "  casetype: civil\n",
      "  doc_id: 수원지방법원성남지원-2016가단17872\n",
      "  info_json: {\"doc_class\": \"1\", \"doc_id\": \"수원지방법원성남지원-2016가단17872\", \"announce_date\": \"2017-03-15T09:00:00.000+09:...\n",
      "  normalized_court: 수원지방법원성남지원\n",
      "  summaries: list[0]\n",
      "  summary_count: 0\n",
      "\n",
      "================================================================================\n",
      "데이터셋: statute_qa\n",
      "================================================================================\n",
      "\n",
      "[train] 12 rows\n",
      "Columns: statute_name, effective_date, statute_type, questions, answers, qa_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: statute\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_법령_질의응답_4.json\n",
      "  _source_zip: TL_01. 민사법_002. 법령_0001. 질의응답.zip\n",
      "  _split: train\n",
      "  _task_type: qa\n",
      "  answers: list[0]\n",
      "  effective_date: 2024-06-26 00:00:00\n",
      "  info_json: {\"doc_class\": \"2\", \"statute_name\": \"민사소송등에서의전자문서이용등에관한규칙\", \"effective_date\": \"2024-06-26 00:00:00\", ...\n",
      "  qa_count: 0\n",
      "  questions: list[0]\n",
      "  statute_name: 민사소송등에서의전자문서이용등에관한규칙\n",
      "  statute_type: 대법원규칙\n",
      "\n",
      "[validation] 2 rows\n",
      "Columns: statute_name, effective_date, statute_type, questions, answers, qa_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: statute\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_법령_질의응답_13.json\n",
      "  _source_zip: VL_01. 민사법_002. 법령_0001. 질의응답.zip\n",
      "  _split: validation\n",
      "  _task_type: qa\n",
      "  answers: list[0]\n",
      "  effective_date: 2021-11-18 00:00:00\n",
      "  info_json: {\"doc_class\": \"2\", \"statute_name\": \"민사조정규칙\", \"effective_date\": \"2021-11-18 00:00:00\", \"proclamation_...\n",
      "  qa_count: 0\n",
      "  questions: list[0]\n",
      "  statute_name: 민사조정규칙\n",
      "  statute_type: 대법원규칙\n",
      "\n",
      "================================================================================\n",
      "데이터셋: trial_decision_qa\n",
      "================================================================================\n",
      "\n",
      "[train] 2,289 rows\n",
      "Columns: doc_id, document_type, decision_date, result, questions, answers, qa_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: trial_decision\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_심결례_질의응답_1019.json\n",
      "  _source_zip: TL_01. 민사법_003. 심결례_0001. 질의응답.zip\n",
      "  _split: train\n",
      "  _task_type: qa\n",
      "  answers: list[0]\n",
      "  decision_date: 2015.01.19\n",
      "  doc_id: 14-진정-1016900\n",
      "  document_type: 국가인권위원회\n",
      "  info_json: {\"doc_class\": \"3\", \"document_type\": \"국가인권위원회\", \"doc_id\": \"14-진정-1016900\", \"decision_date\": \"2015.01....\n",
      "  qa_count: 0\n",
      "  questions: list[0]\n",
      "  result: None\n",
      "\n",
      "[validation] 279 rows\n",
      "Columns: doc_id, document_type, decision_date, result, questions, answers, qa_count, info_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: trial_decision\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_심결례_질의응답_1145.json\n",
      "  _source_zip: VL_01. 민사법_003. 심결례_0001. 질의응답.zip\n",
      "  _split: validation\n",
      "  _task_type: qa\n",
      "  answers: list[0]\n",
      "  decision_date: 2020.02.17\n",
      "  doc_id: 18-진정-0545600\n",
      "  document_type: 국가인권위원회\n",
      "  info_json: {\"doc_class\": \"3\", \"document_type\": \"국가인권위원회\", \"doc_id\": \"18-진정-0545600\", \"decision_date\": \"2020.02....\n",
      "  qa_count: 0\n",
      "  questions: list[0]\n",
      "  result: None\n",
      "\n",
      "================================================================================\n",
      "데이터셋: trial_decision_summary\n",
      "================================================================================\n",
      "\n",
      "[train] 1,100 rows\n",
      "Columns: raw_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: trial_decision\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_심결례_요약_1021.json\n",
      "  _source_zip: TL_01. 민사법_003. 심결례_0002. 요약.zip\n",
      "  _split: train\n",
      "  _task_type: summary\n",
      "  raw_json: {\"info\": {\"doc_class\": \"3\", \"document_type\": \"국가인권위원회\", \"doc_id\": \"16-진정-0317900\", \"decision_date\": ...\n",
      "\n",
      "[validation] 140 rows\n",
      "Columns: raw_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: trial_decision\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_심결례_요약_103.json\n",
      "  _source_zip: VL_01. 민사법_003. 심결례_0002. 요약.zip\n",
      "  _split: validation\n",
      "  _task_type: summary\n",
      "  raw_json: {\"info\": {\"doc_class\": \"3\", \"document_type\": \"중앙행정심판위원회\", \"doc_id\": \"2021-14414\", \"decision_date\": \"...\n",
      "\n",
      "================================================================================\n",
      "데이터셋: interpretation_qa\n",
      "================================================================================\n",
      "\n",
      "[train] 258 rows\n",
      "Columns: raw_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: interpretation\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_유권해석_질의응답_113.json\n",
      "  _source_zip: TL_01. 민사법_004. 유권해석_0001. 질의응답.zip\n",
      "  _split: train\n",
      "  _task_type: qa\n",
      "  raw_json: {\"info\": {\"doc_class\": \"4\", \"doc_id\": \"고용노동부-질의회시-PDF-651bb70-근로기준과-2928\", \"response_institute\": \"고용...\n",
      "\n",
      "[validation] 38 rows\n",
      "Columns: raw_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: interpretation\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_유권해석_질의응답_176.json\n",
      "  _source_zip: VL_01. 민사법_004. 유권해석_0001. 질의응답.zip\n",
      "  _split: validation\n",
      "  _task_type: qa\n",
      "  raw_json: {\"info\": {\"doc_class\": \"4\", \"doc_id\": \"고용노동부-질의회시-PDF-0d94d01-근로기준팀-3765\", \"response_institute\": \"고용...\n",
      "\n",
      "================================================================================\n",
      "데이터셋: interpretation_summary\n",
      "================================================================================\n",
      "\n",
      "[train] 152 rows\n",
      "Columns: raw_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: interpretation\n",
      "  _row_id: train-0000000\n",
      "  _source_json: /민사법_유권해석_요약_372.json\n",
      "  _source_zip: TL_01. 민사법_004. 유권해석_0002. 요약.zip\n",
      "  _split: train\n",
      "  _task_type: summary\n",
      "  raw_json: {\"info\": {\"doc_class\": \"4\", \"doc_id\": \"고용노동부-질의회시-PDF-0d94d01-임금근로시간정책팀-1689\", \"response_institute\":...\n",
      "\n",
      "[validation] 28 rows\n",
      "Columns: raw_json, _source_zip, _source_json, _data_type, _task_type, _row_id, _split\n",
      "\n",
      "첫 번째 샘플:\n",
      "  _data_type: interpretation\n",
      "  _row_id: validation-0000000\n",
      "  _source_json: /민사법_유권해석_요약_450.json\n",
      "  _source_zip: VL_01. 민사법_004. 유권해석_0002. 요약.zip\n",
      "  _split: validation\n",
      "  _task_type: summary\n",
      "  raw_json: {\"info\": {\"doc_class\": \"4\", \"doc_id\": \"고용노동부-질의회시-PDF-2dd3e0c-산안(건안)_68307-41\", \"response_institute\"...\n"
     ]
    }
   ],
   "source": [
    "# 각 데이터셋 샘플 확인\n",
    "print(\"=\"*80)\n",
    "print(\"데이터셋 샘플 확인\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for dataset_name, ds_dict in typed_datasets.items():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"데이터셋: {dataset_name}\")\n",
    "    print('='*80)\n",
    "    \n",
    "    for split in [\"train\", \"validation\"]:\n",
    "        if split not in ds_dict:\n",
    "            continue\n",
    "        \n",
    "        ds = ds_dict[split]\n",
    "        print(f\"\\n[{split}] {len(ds):,} rows\")\n",
    "        print(f\"Columns: {', '.join(ds.column_names[:15])}\")\n",
    "        if len(ds.column_names) > 15:\n",
    "            print(f\"         ... and {len(ds.column_names) - 15} more\")\n",
    "        \n",
    "        # 첫 번째 샘플 출력\n",
    "        if len(ds) > 0:\n",
    "            print(f\"\\n첫 번째 샘플:\")\n",
    "            sample = ds[0]\n",
    "            for key, value in sorted(sample.items()):\n",
    "                if key.startswith('_'):\n",
    "                    print(f\"  {key}: {value}\")\n",
    "                elif isinstance(value, str):\n",
    "                    print(f\"  {key}: {value[:100]}...\" if len(value) > 100 else f\"  {key}: {value}\")\n",
    "                elif isinstance(value, list):\n",
    "                    print(f\"  {key}: list[{len(value)}]\")\n",
    "                    if len(value) > 0:\n",
    "                        print(f\"    └─ 첫 항목: {str(value[0])[:80]}...\")\n",
    "                else:\n",
    "                    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a17dff64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터셋 저장 중: /mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/processed_datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 12/12 [00:00<00:00, 425.77 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 91.96 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2510/2510 [00:00<00:00, 11547.17 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 406/406 [00:00<00:00, 7462.06 examples/s]\n",
      "Saving the dataset (2/2 shards): 100%|██████████| 76291/76291 [00:05<00:00, 13483.16 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9527/9527 [00:00<00:00, 13334.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 410/410 [00:00<00:00, 12964.12 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 66/66 [00:00<00:00, 2856.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 73065/73065 [00:00<00:00, 134185.07 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9135/9135 [00:00<00:00, 99952.70 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 3228/3228 [00:00<00:00, 70868.12 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 392/392 [00:00<00:00, 15399.87 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 12/12 [00:00<00:00, 578.44 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2/2 [00:00<00:00, 186.83 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 2289/2289 [00:00<00:00, 61768.24 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 279/279 [00:00<00:00, 11337.71 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 1100/1100 [00:00<00:00, 10014.77 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 140/140 [00:00<00:00, 4298.42 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 258/258 [00:00<00:00, 9944.59 examples/s] \n",
      "Saving the dataset (1/1 shards): 100%|██████████| 38/38 [00:00<00:00, 1732.83 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 152/152 [00:00<00:00, 6032.74 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 28/28 [00:00<00:00, 1324.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ 저장 완료: /mnt/d/data/01.민사법 LLM 사전학습 및 Instruction Tuning 데이터/processed_datasets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 데이터셋 저장\n",
    "output_dir = str(BASE_DIR) + \"/processed_datasets\"\n",
    "print(f\"데이터셋 저장 중: {output_dir}\")\n",
    "typed_datasets.save_to_disk(output_dir)\n",
    "print(f\"✓ 저장 완료: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "003d399c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 데이터셋 수: 11\n",
      "데이터셋 키들: ['statute_source', 'trial_decision_source', 'precedent_source', 'interpretation_source', 'precedent_qa', 'precedent_summary', 'statute_qa', 'trial_decision_qa', 'trial_decision_summary', 'interpretation_qa', 'interpretation_summary']\n",
      "\n",
      "statute_source:\n",
      "  - train: 12 rows\n",
      "  - validation: 2 rows\n",
      "\n",
      "trial_decision_source:\n",
      "  - train: 2510 rows\n",
      "  - validation: 406 rows\n",
      "\n",
      "precedent_source:\n",
      "  - train: 76291 rows\n",
      "  - validation: 9527 rows\n",
      "\n",
      "interpretation_source:\n",
      "  - train: 410 rows\n",
      "  - validation: 66 rows\n",
      "\n",
      "precedent_qa:\n",
      "  - train: 73065 rows\n",
      "  - validation: 9135 rows\n",
      "\n",
      "precedent_summary:\n",
      "  - train: 3228 rows\n",
      "  - validation: 392 rows\n",
      "\n",
      "statute_qa:\n",
      "  - train: 12 rows\n",
      "  - validation: 2 rows\n",
      "\n",
      "trial_decision_qa:\n",
      "  - train: 2289 rows\n",
      "  - validation: 279 rows\n",
      "\n",
      "trial_decision_summary:\n",
      "  - train: 1100 rows\n",
      "  - validation: 140 rows\n",
      "\n",
      "interpretation_qa:\n",
      "  - train: 258 rows\n",
      "  - validation: 38 rows\n",
      "\n",
      "interpretation_summary:\n",
      "  - train: 152 rows\n",
      "  - validation: 28 rows\n"
     ]
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "# typed_datasets가 이미 딕셔너리 형태라고 가정\n",
    "# 각 키의 값이 DatasetDict인 경우\n",
    "\n",
    "# 방법 1: typed_datasets가 일반 딕셔너리인 경우\n",
    "if isinstance(typed_datasets, dict) and not isinstance(typed_datasets, DatasetDict):\n",
    "    typed_datasets = DatasetDict(typed_datasets)\n",
    "\n",
    "# 방법 2: 중첩된 구조인 경우 (각 키마다 train/validation이 있는 경우)\n",
    "# 이미 DatasetDict 형태이므로 변환 불필요\n",
    "# typed_datasets의 각 키는 이미 DatasetDict입니다\n",
    "\n",
    "# 사용 예시:\n",
    "print(f\"총 데이터셋 수: {len(typed_datasets)}\")\n",
    "print(f\"데이터셋 키들: {list(typed_datasets.keys())}\")\n",
    "\n",
    "# 각 데이터셋 확인\n",
    "for key, dataset_dict in typed_datasets.items():\n",
    "    print(f\"\\n{key}:\")\n",
    "    print(f\"  - train: {len(dataset_dict['train'])} rows\")\n",
    "    print(f\"  - validation: {len(dataset_dict['validation'])} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "72bda902",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Config 추가: statute_source\n",
      "Config 추가: trial_decision_source\n",
      "Config 추가: precedent_source\n",
      "Config 추가: interpretation_source\n",
      "Config 추가: precedent_qa\n",
      "Config 추가: precedent_summary\n",
      "Config 추가: statute_qa\n",
      "Config 추가: trial_decision_qa\n",
      "Config 추가: trial_decision_summary\n",
      "Config 추가: interpretation_qa\n",
      "Config 추가: interpretation_summary\n",
      "\n",
      "총 11개의 config 준비됨:\n",
      "  - statute_source\n",
      "  - trial_decision_source\n",
      "  - precedent_source\n",
      "  - interpretation_source\n",
      "  - precedent_qa\n",
      "  - precedent_summary\n",
      "  - statute_qa\n",
      "  - trial_decision_qa\n",
      "  - trial_decision_summary\n",
      "  - interpretation_qa\n",
      "  - interpretation_summary\n",
      "\n",
      "업로드 중: statute_source\n",
      "  최소 split 크기: 2, num_proc: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.45ba/s]s/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 48.54ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.45ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 48.54ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  110kB /  110kB, 61.3kB/s  \n",
      "New Data Upload: 100%|██████████|  110kB /  110kB, 61.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  110kB /  110kB, 61.3kB/s  <00:03,  3.56s/ shards]\n",
      "New Data Upload: 100%|██████████|  110kB /  110kB, 61.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  243kB /  243kB,  111kB/s  <00:03,  3.56s/ shards]\n",
      "New Data Upload: 100%|██████████|  243kB /  243kB,  111kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  243kB /  243kB,  111kB/s  <00:00,  1.70s/ shards]\n",
      "New Data Upload: 100%|██████████|  243kB /  243kB,  111kB/s  \n",
      "Uploading the dataset shards (num_proc=2): 100%|██████████| 2/2 [00:04<00:00,  2.04s/ shards]\n",
      "Uploading the dataset shards (num_proc=2): 100%|██████████| 2/2 [00:04<00:00,  2.04s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.77ba/s]/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 180.19ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 180.19ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 14.6kB / 14.6kB, 12.2kB/s  \n",
      "New Data Upload: 100%|██████████| 14.6kB / 14.6kB, 12.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 14.6kB / 14.6kB, 12.2kB/s  <00:02,  2.32s/ shards]\n",
      "New Data Upload: 100%|██████████| 14.6kB / 14.6kB, 12.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 84.9kB / 84.9kB, 47.1kB/s  <00:02,  2.32s/ shards]\n",
      "New Data Upload: 100%|██████████| 84.9kB / 84.9kB, 47.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 84.9kB / 84.9kB, 47.1kB/s  <00:00,  1.91s/ shards]\n",
      "New Data Upload: 100%|██████████| 84.9kB / 84.9kB, 47.1kB/s  \n",
      "Uploading the dataset shards (num_proc=2): 100%|██████████| 2/2 [00:04<00:00,  2.04s/ shards]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: trial_decision_source\n",
      "  최소 split 크기: 406, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 80.00ba/s]rds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 80.00ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.76ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.76ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 80.49ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 80.49ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.29ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.29ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 79.73ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 79.73ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 79.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 79.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 78.09ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 78.09ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 82.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 82.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.71ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.71ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.65ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.65ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 78.32ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 78.32ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.20ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.20ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  963kB /  963kB,  370kB/s  \n",
      "New Data Upload: 100%|██████████|  963kB /  963kB,  370kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 58.98ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  963kB /  963kB,  370kB/s  \n",
      "New Data Upload: 100%|██████████|  963kB /  963kB,  370kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 58.98ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 1.06MB / 1.06MB,  409kB/s  \n",
      "New Data Upload: 100%|██████████| 1.06MB / 1.06MB,  409kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 86.64ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  965kB /  965kB,  402kB/s  \n",
      "New Data Upload: 100%|██████████|  965kB /  965kB,  402kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.06MB / 1.06MB,  409kB/s  \n",
      "New Data Upload: 100%|██████████| 1.06MB / 1.06MB,  409kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 86.64ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  965kB /  965kB,  402kB/s  \n",
      "New Data Upload: 100%|██████████|  965kB /  965kB,  402kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.20ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.20ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 1.00MB / 1.00MB,  385kB/s  \n",
      "New Data Upload: 100%|██████████| 1.00MB / 1.00MB,  385kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.00MB / 1.00MB,  385kB/s  05<00:11,  1.06 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.00MB / 1.00MB,  385kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 68.91ba/s]1.06 shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 68.91ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 1.05MB / 1.05MB,  436kB/s  \n",
      "New Data Upload: 100%|██████████| 1.05MB / 1.05MB,  436kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.05MB / 1.05MB,  436kB/s  \n",
      "New Data Upload: 100%|██████████| 1.05MB / 1.05MB,  436kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  969kB /  969kB,  372kB/s  \n",
      "New Data Upload: 100%|██████████|  969kB /  969kB,  372kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  969kB /  969kB,  372kB/s  05<00:06,  1.59 shards/s]\n",
      "New Data Upload: 100%|██████████|  969kB /  969kB,  372kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  993kB /  993kB,  414kB/s  05<00:06,  1.59 shards/s]\n",
      "New Data Upload: 100%|██████████|  993kB /  993kB,  414kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  993kB /  993kB,  414kB/s  \n",
      "New Data Upload: 100%|██████████|  993kB /  993kB,  414kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  962kB /  962kB,  401kB/s  \n",
      "New Data Upload: 100%|██████████|  962kB /  962kB,  401kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  962kB /  962kB,  401kB/s  06<00:03,  2.21 shards/s]\n",
      "New Data Upload: 100%|██████████|  962kB /  962kB,  401kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.07MB / 1.07MB,  411kB/s  06<00:03,  2.21 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.07MB / 1.07MB,  411kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.07MB / 1.07MB,  411kB/s  06<00:03,  2.15 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.07MB / 1.07MB,  411kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.05MB / 1.05MB,  439kB/s  06<00:03,  2.15 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.05MB / 1.05MB,  439kB/s  \n",
      "Processing Files (0 / 1):  54%|█████▎    |  526kB /  979kB,  657kB/s  :07<00:02,  2.57 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 1.05MB / 1.05MB,  439kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  942kB /  942kB,  392kB/s  \n",
      "New Data Upload: 100%|██████████|  942kB /  942kB,  392kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  942kB /  942kB,  392kB/s  :07<00:01,  2.82 shards/s]\n",
      "New Data Upload: 100%|██████████|  942kB /  942kB,  392kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.10MB / 1.10MB,  423kB/s  :07<00:01,  2.82 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.10MB / 1.10MB,  423kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.10MB / 1.10MB,  423kB/s  :07<00:01,  2.46 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.10MB / 1.10MB,  423kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.13MB / 1.13MB,  470kB/s  :07<00:01,  2.46 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.13MB / 1.13MB,  470kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.13MB / 1.13MB,  470kB/s  :07<00:00,  3.07 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.13MB / 1.13MB,  470kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  935kB /  935kB,  360kB/s  :07<00:00,  3.07 shards/s]\n",
      "New Data Upload: 100%|██████████|  935kB /  935kB,  360kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  935kB /  935kB,  360kB/s  \n",
      "New Data Upload: 100%|██████████|  935kB /  935kB,  360kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  979kB /  979kB,  408kB/s  :08<00:00,  2.67 shards/s]\n",
      "New Data Upload: 100%|██████████|  979kB /  979kB,  408kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  979kB /  979kB,  408kB/s  :08<00:00,  3.10 shards/s]\n",
      "New Data Upload: 100%|██████████|  979kB /  979kB,  408kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.12MB / 1.12MB,  432kB/s  :08<00:00,  3.10 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.12MB / 1.12MB,  432kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 1.12MB / 1.12MB,  432kB/s  :09<00:00,  2.79 shards/s]\n",
      "New Data Upload: 100%|██████████| 1.12MB / 1.12MB,  432kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:09<00:00,  1.72 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.96ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.17ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.17ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.79ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.12ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.12ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.60ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.60ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.61ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.61ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 98.84ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 98.84ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 127.84ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 127.84ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 101.12ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 101.12ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.49ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 105.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 105.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 103.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 103.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 24.58ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 24.58ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 108.35ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 108.35ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  157kB /  157kB, 78.5kB/s  \n",
      "New Data Upload: 100%|██████████|  157kB /  157kB, 78.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  162kB /  162kB, 81.2kB/s  \n",
      "New Data Upload: 100%|██████████|  162kB /  162kB, 81.2kB/s  1/16 [00:03<00:55,  3.69s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████|  157kB /  157kB, 78.5kB/s  \n",
      "New Data Upload: 100%|██████████|  157kB /  157kB, 78.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  162kB /  162kB, 81.2kB/s  \n",
      "New Data Upload: 100%|██████████|  162kB /  162kB, 81.2kB/s  1/16 [00:03<00:55,  3.69s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████|  154kB /  154kB, 85.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  181kB /  181kB, 90.7kB/s  \n",
      "New Data Upload: 100%|██████████|  154kB /  154kB, 85.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  154kB /  154kB, 85.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  181kB /  181kB, 90.7kB/s  \n",
      "New Data Upload: 100%|██████████|  154kB /  154kB, 85.7kB/s  \n",
      "New Data Upload: 100%|██████████|  181kB /  181kB, 90.7kB/s  \n",
      "New Data Upload: 100%|██████████|  181kB /  181kB, 90.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  181kB /  181kB,  100kB/s  \n",
      "New Data Upload: 100%|██████████|  181kB /  181kB,  100kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  181kB /  181kB,  100kB/s  03<00:06,  1.74 shards/s]\n",
      "New Data Upload: 100%|██████████|  181kB /  181kB,  100kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  153kB /  153kB, 85.0kB/s  03<00:06,  1.74 shards/s]\n",
      "New Data Upload: 100%|██████████|  153kB /  153kB, 85.0kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████|  153kB /  153kB, 85.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  174kB /  174kB, 86.9kB/s  \n",
      "New Data Upload: 100%|██████████|  174kB /  174kB, 86.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  180kB /  180kB, 82.0kB/s  \n",
      "New Data Upload: 100%|██████████|  180kB /  180kB, 82.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  174kB /  174kB, 86.9kB/s  03<00:02,  3.12 shards/s]\n",
      "New Data Upload: 100%|██████████|  174kB /  174kB, 86.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  180kB /  180kB, 82.0kB/s  \n",
      "New Data Upload: 100%|██████████|  180kB /  180kB, 82.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  149kB /  149kB, 83.0kB/s  03<00:02,  3.12 shards/s]\n",
      "New Data Upload: 100%|██████████|  149kB /  149kB, 83.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  149kB /  149kB, 83.0kB/s  \n",
      "New Data Upload: 100%|██████████|  149kB /  149kB, 83.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  173kB /  173kB, 96.2kB/s  \n",
      "New Data Upload: 100%|██████████|  173kB /  173kB, 96.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  181kB /  181kB,  101kB/s  \n",
      "New Data Upload: 100%|██████████|  181kB /  181kB,  101kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  173kB /  173kB, 96.2kB/s  \n",
      "New Data Upload: 100%|██████████|  173kB /  173kB, 96.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  181kB /  181kB,  101kB/s  \n",
      "New Data Upload: 100%|██████████|  181kB /  181kB,  101kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  223kB /  223kB,  101kB/s  \n",
      "New Data Upload: 100%|██████████|  223kB /  223kB,  101kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  223kB /  223kB,  101kB/s  :04<00:00,  5.27 shards/s]\n",
      "New Data Upload: 100%|██████████|  223kB /  223kB,  101kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  152kB /  152kB, 76.2kB/s  :04<00:00,  5.27 shards/s]\n",
      "New Data Upload: 100%|██████████|  152kB /  152kB, 76.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  152kB /  152kB, 76.2kB/s  \n",
      "New Data Upload: 100%|██████████|  152kB /  152kB, 76.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  183kB /  183kB, 91.7kB/s  \n",
      "New Data Upload: 100%|██████████|  183kB /  183kB, 91.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  183kB /  183kB, 91.7kB/s  \n",
      "New Data Upload: 100%|██████████|  183kB /  183kB, 91.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  147kB /  147kB, 81.7kB/s  \n",
      "New Data Upload: 100%|██████████|  147kB /  147kB, 81.7kB/s  \n",
      "Uploading the dataset shards (num_proc=16):  94%|█████████▍| 15/16 [00:04<00:00,  5.62 shards/s]\n",
      "New Data Upload: 100%|██████████|  147kB /  147kB, 81.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  193kB /  193kB, 68.8kB/s  :04<00:00,  5.62 shards/s]\n",
      "New Data Upload: 100%|██████████|  193kB /  193kB, 68.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  193kB /  193kB, 68.8kB/s  \n",
      "New Data Upload: 100%|██████████|  193kB /  193kB, 68.8kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:04<00:00,  3.21 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: precedent_source\n",
      "  최소 split 크기: 9527, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  9.47ba/s]rds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  9.47ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 21.2MB / 21.2MB, 5.58MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.2MB / 21.2MB, 5.30MB/s  \n",
      "New Data Upload: 100%|██████████| 21.2MB / 21.2MB, 5.30MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.2MB / 21.2MB, 5.30MB/s   10.47ba/s]\n",
      "New Data Upload: 100%|██████████| 21.2MB / 21.2MB, 5.30MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 10.47ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 19.1MB / 19.1MB, 4.77MB/s  \n",
      "New Data Upload: 100%|██████████| 19.1MB / 19.1MB, 4.77MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.1MB / 19.1MB, 4.77MB/s  \n",
      "New Data Upload: 100%|██████████| 19.1MB / 19.1MB, 4.77MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  9.05ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  9.05ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.96ba/s]1.13s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 20.6MB / 20.6MB, 3.95MB/s  \n",
      "New Data Upload: 100%|██████████| 20.6MB / 20.6MB, 3.95MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.96ba/s]1.13s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 20.6MB / 20.6MB, 3.95MB/s  \n",
      "New Data Upload: 100%|██████████| 20.6MB / 20.6MB, 3.95MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.6MB / 25.6MB, 5.56MB/s  \n",
      "New Data Upload: 100%|██████████| 25.6MB / 25.6MB, 5.56MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.28ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 25.6MB / 25.6MB, 5.56MB/s  \n",
      "New Data Upload: 100%|██████████| 25.6MB / 25.6MB, 5.56MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.28ba/s]\n",
      "Processing Files (0 / 1):  99%|█████████▉| 27.8MB / 28.0MB, 6.95MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.0MB / 28.0MB, 5.60MB/s  \n",
      "New Data Upload: 100%|██████████| 28.0MB / 28.0MB, 5.60MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.0MB / 28.0MB, 5.60MB/s    6.70ba/s]\n",
      "New Data Upload: 100%|██████████| 28.0MB / 28.0MB, 5.60MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.70ba/s]\n",
      "Processing Files (0 / 1):  26%|██▌       | 7.35MB / 28.4MB, 3.34MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.81ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.4MB / 28.4MB, 5.26MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.81ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.4MB / 28.4MB, 5.26MB/s  \n",
      "New Data Upload: 100%|██████████| 28.4MB / 28.4MB, 5.26MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 29.0MB / 29.0MB, 5.58MB/s  \n",
      "New Data Upload: 100%|██████████| 29.0MB / 29.0MB, 5.58MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 29.0MB / 29.0MB, 5.58MB/s  \n",
      "New Data Upload: 100%|██████████| 29.0MB / 29.0MB, 5.58MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.58ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.58ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.24ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.24ba/s]\n",
      "Processing Files (0 / 1):  39%|███▊      | 11.0MB / 28.5MB, 2.75MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.20ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.5MB / 28.5MB, 2.85MB/s  \n",
      "New Data Upload: 100%|██████████| 28.5MB / 28.5MB, 2.85MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.5MB / 28.5MB, 2.85MB/s  25<01:33, 11.70s/ shards]\n",
      "New Data Upload: 100%|██████████| 28.5MB / 28.5MB, 2.85MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.11ba/s]1.70s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.5MB / 28.5MB, 4.75MB/s  \n",
      "New Data Upload: 100%|██████████| 28.5MB / 28.5MB, 4.75MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.11ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.5MB / 28.5MB, 4.75MB/s  \n",
      "New Data Upload: 100%|██████████| 28.5MB / 28.5MB, 4.75MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.6MB / 28.6MB, 1.66MB/s  \n",
      "New Data Upload: 100%|██████████| 28.6MB / 28.6MB, 1.66MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.6MB / 28.6MB, 1.66MB/s  :31<00:42,  7.07s/ shards]\n",
      "New Data Upload: 100%|██████████| 28.6MB / 28.6MB, 1.66MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.99ba/s] 7.07s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.99ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.96ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.8MB / 28.8MB, 2.67MB/s  \n",
      "New Data Upload: 100%|██████████| 28.8MB / 28.8MB, 2.67MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.8MB / 28.8MB, 2.67MB/s  :46<00:47,  9.47s/ shards]\n",
      "New Data Upload: 100%|██████████| 28.8MB / 28.8MB, 2.67MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 29.2MB / 29.2MB, 4.86MB/s  :46<00:47,  9.47s/ shards]\n",
      "New Data Upload: 100%|██████████| 29.2MB / 29.2MB, 4.86MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 29.2MB / 29.2MB, 4.86MB/s  \n",
      "New Data Upload: 100%|██████████| 29.2MB / 29.2MB, 4.86MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.6MB / 28.6MB, 2.60MB/s  \n",
      "New Data Upload: 100%|██████████| 28.6MB / 28.6MB, 2.60MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.6MB / 28.6MB, 2.60MB/s  :54<00:19,  6.46s/ shards]\n",
      "New Data Upload: 100%|██████████| 28.6MB / 28.6MB, 2.60MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.38ba/s] 6.46s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.38ba/s]\n",
      "Processing Files (0 / 1):  11%|█         | 3.15MB / 28.6MB, 1.75MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.23ba/s] 6.69s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.6MB / 28.6MB, 5.49MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  7.23ba/s] 6.69s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.6MB / 28.6MB, 5.49MB/s  \n",
      "New Data Upload: 100%|██████████| 28.6MB / 28.6MB, 5.49MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  8.14ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  8.14ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 28.4MB / 28.4MB, 2.73MB/s  \n",
      "New Data Upload: 100%|██████████| 28.4MB / 28.4MB, 2.73MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.4MB / 28.4MB, 2.73MB/s  :12<00:08,  8.06s/ shards]\n",
      "New Data Upload: 100%|██████████| 28.4MB / 28.4MB, 2.73MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 24.1MB / 24.1MB, 5.03MB/s  :12<00:08,  8.06s/ shards]\n",
      "New Data Upload: 100%|██████████| 24.1MB / 24.1MB, 5.03MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 24.1MB / 24.1MB, 5.03MB/s  :14<00:00,  5.99s/ shards]\n",
      "New Data Upload: 100%|██████████| 24.1MB / 24.1MB, 5.03MB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [02:14<00:00,  8.40s/ shards]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 40.51ba/s]rds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 40.51ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 43.42ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 43.42ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 47.15ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 47.15ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 45.16ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 45.16ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 2.49MB / 2.49MB,  831kB/s  \n",
      "New Data Upload: 100%|██████████| 2.49MB / 2.49MB,  831kB/s  1/16 [00:06<01:30,  6.06s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 36.12ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 2.49MB / 2.49MB,  831kB/s  \n",
      "New Data Upload: 100%|██████████| 2.49MB / 2.49MB,  831kB/s  1/16 [00:06<01:30,  6.06s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 36.12ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 40.34ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 40.34ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 39.73ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 39.73ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.46ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.28MB / 3.28MB, 1.09MB/s  \n",
      "New Data Upload: 100%|██████████| 3.28MB / 3.28MB, 1.09MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.46ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.28MB / 3.28MB, 1.09MB/s  \n",
      "New Data Upload: 100%|██████████| 3.28MB / 3.28MB, 1.09MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 2.31MB / 2.31MB,  398kB/s  \n",
      "New Data Upload: 100%|██████████| 2.31MB / 2.31MB,  398kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 2.31MB / 2.31MB,  398kB/s  09<00:33,  2.56s/ shards]\n",
      "New Data Upload: 100%|██████████| 2.31MB / 2.31MB,  398kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.62MB / 3.62MB, 1.29MB/s  09<00:33,  2.56s/ shards]\n",
      "New Data Upload: 100%|██████████| 3.62MB / 3.62MB, 1.29MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.62MB / 3.62MB, 1.29MB/s  09<00:19,  1.61s/ shards]\n",
      "New Data Upload: 100%|██████████| 3.62MB / 3.62MB, 1.29MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 40.81ba/s]1.61s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 40.81ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.62MB / 3.62MB, 1.29MB/s  \n",
      "New Data Upload: 100%|██████████| 3.62MB / 3.62MB, 1.29MB/s  \n",
      "Processing Files (0 / 1):  88%|████████▊ | 3.15MB / 3.57MB, 1.75MB/s  10<00:15,  1.37s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.62MB / 3.62MB, 1.29MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 2.63MB / 2.63MB,  439kB/s  \n",
      "New Data Upload: 100%|██████████| 2.63MB / 2.63MB,  439kB/s  6/16 [00:11<00:10,  1.05s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 2.63MB / 2.63MB,  439kB/s  \n",
      "New Data Upload: 100%|██████████| 2.63MB / 2.63MB,  439kB/s  6/16 [00:11<00:10,  1.05s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 33.51ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 33.51ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  \n",
      "New Data Upload: 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  11<00:08,  1.11 shards/s]\n",
      "New Data Upload: 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 38.18ba/s]1.11 shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 38.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.57ba/s]\n",
      "Processing Files (0 / 0): |          |  0.00B /  0.00B            /s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.33ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.49MB / 3.49MB, 1.16MB/s  \n",
      "Processing Files (0 / 1):  29%|██▉       | 1.05MB / 3.57MB,  657kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.33ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.49MB / 3.49MB, 1.16MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.81ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.81ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  \n",
      "New Data Upload: 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  15<00:09,  1.38s/ shards]\n",
      "New Data Upload: 100%|██████████| 3.57MB / 3.57MB, 1.27MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.55MB / 3.55MB,  633kB/s  15<00:09,  1.38s/ shards]\n",
      "New Data Upload: 100%|██████████| 3.55MB / 3.55MB,  633kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 35.84ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.55MB / 3.55MB,  633kB/s  \n",
      "New Data Upload: 100%|██████████| 3.55MB / 3.55MB,  633kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 35.84ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.55MB / 3.55MB, 1.27MB/s  \n",
      "New Data Upload: 100%|██████████| 3.55MB / 3.55MB, 1.27MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.55MB / 3.55MB, 1.27MB/s  :16<00:04,  1.12 shards/s]\n",
      "New Data Upload: 100%|██████████| 3.55MB / 3.55MB, 1.27MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 39.63ba/s] 1.12 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.68MB / 3.68MB, 1.23MB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 39.63ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.68MB / 3.68MB, 1.23MB/s  \n",
      "New Data Upload: 100%|██████████| 3.68MB / 3.68MB, 1.23MB/s  \n",
      "New Data Upload: 100%|██████████| 3.68MB / 3.68MB, 1.23MB/s  12/16 [00:17<00:03,  1.21 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 3.52MB / 3.52MB, 1.26MB/s  :17<00:03,  1.21 shards/s]\n",
      "New Data Upload: 100%|██████████| 3.52MB / 3.52MB, 1.26MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.52MB / 3.52MB, 1.26MB/s  :18<00:02,  1.23 shards/s]\n",
      "New Data Upload: 100%|██████████| 3.52MB / 3.52MB, 1.26MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.63MB / 3.63MB, 1.30MB/s  :18<00:02,  1.23 shards/s]\n",
      "New Data Upload: 100%|██████████| 3.63MB / 3.63MB, 1.30MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.63MB / 3.63MB, 1.30MB/s  :19<00:01,  1.08 shards/s]\n",
      "New Data Upload: 100%|██████████| 3.63MB / 3.63MB, 1.30MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.25MB / 3.25MB, 1.08MB/s  :19<00:01,  1.08 shards/s]\n",
      "New Data Upload: 100%|██████████| 3.25MB / 3.25MB, 1.08MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.25MB / 3.25MB, 1.08MB/s  :21<00:01,  1.26s/ shards]\n",
      "New Data Upload: 100%|██████████| 3.25MB / 3.25MB, 1.08MB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.52MB / 3.52MB,  439kB/s  :21<00:01,  1.26s/ shards]\n",
      "New Data Upload: 100%|██████████| 3.52MB / 3.52MB,  439kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 3.52MB / 3.52MB,  439kB/s  :25<00:00,  2.10s/ shards]\n",
      "New Data Upload: 100%|██████████| 3.52MB / 3.52MB,  439kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:25<00:00,  1.60s/ shards]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: interpretation_source\n",
      "  최소 split 크기: 66, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 156.46ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 110.93ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 156.46ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 110.93ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 106.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.66ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 106.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.66ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.91ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.91ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 71.91ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 153.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 71.91ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 153.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 135.03ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 117.14ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 117.14ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 96.91ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 96.91ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.23ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.23ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 27.38ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 27.38ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.31ba/s]\n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 48.1kB / 48.1kB, 34.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 47.3kB / 47.3kB, 33.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 49.8kB / 49.8kB, 35.5kB/s  \n",
      "New Data Upload: 100%|██████████| 47.3kB / 47.3kB, 33.8kB/s  \n",
      "New Data Upload: 100%|██████████| 48.1kB / 48.1kB, 34.4kB/s  \n",
      "New Data Upload: 100%|██████████| 49.8kB / 49.8kB, 35.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 48.1kB / 48.1kB, 34.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 47.3kB / 47.3kB, 33.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 49.8kB / 49.8kB, 35.5kB/s  \n",
      "New Data Upload: 100%|██████████| 47.3kB / 47.3kB, 33.8kB/s  \n",
      "New Data Upload: 100%|██████████| 48.1kB / 48.1kB, 34.4kB/s  \n",
      "New Data Upload: 100%|██████████| 49.8kB / 49.8kB, 35.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 45.2kB / 45.2kB, 32.3kB/s  03<00:45,  3.02s/ shards]\n",
      "New Data Upload: 100%|██████████| 45.2kB / 45.2kB, 32.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 45.2kB / 45.2kB, 32.3kB/s  \n",
      "New Data Upload: 100%|██████████| 45.2kB / 45.2kB, 32.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.9kB / 42.9kB, 30.7kB/s  \n",
      "New Data Upload: 100%|██████████| 42.9kB / 42.9kB, 30.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.9kB / 42.9kB, 30.7kB/s  03<00:05,  2.12 shards/s]\n",
      "New Data Upload: 100%|██████████| 42.9kB / 42.9kB, 30.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 41.1kB / 41.1kB, 29.3kB/s  03<00:05,  2.12 shards/s]\n",
      "New Data Upload: 100%|██████████| 41.1kB / 41.1kB, 29.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 41.1kB / 41.1kB, 29.3kB/s  \n",
      "New Data Upload: 100%|██████████| 41.1kB / 41.1kB, 29.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 50.5kB / 50.5kB, 36.0kB/s  \n",
      "New Data Upload: 100%|██████████| 50.5kB / 50.5kB, 36.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 50.5kB / 50.5kB, 36.0kB/s  \n",
      "New Data Upload: 100%|██████████| 50.5kB / 50.5kB, 36.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 51.2kB / 51.2kB, 32.0kB/s  \n",
      "New Data Upload: 100%|██████████| 51.2kB / 51.2kB, 32.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 38.5kB / 38.5kB, 27.5kB/s  03<00:02,  3.68 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 51.2kB / 51.2kB, 32.0kB/s  \n",
      "New Data Upload: 100%|██████████| 51.2kB / 51.2kB, 32.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 38.5kB / 38.5kB, 27.5kB/s  03<00:02,  3.68 shards/s]\n",
      "New Data Upload: 100%|██████████| 38.5kB / 38.5kB, 27.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 49.8kB / 49.8kB, 31.1kB/s  \n",
      "New Data Upload: 100%|██████████| 49.8kB / 49.8kB, 31.1kB/s  \n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 49.8kB / 49.8kB, 31.1kB/s  \n",
      "New Data Upload: 100%|██████████| 49.8kB / 49.8kB, 31.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 48.2kB / 48.2kB, 30.1kB/s  \n",
      "New Data Upload: 100%|██████████| 48.2kB / 48.2kB, 30.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 48.2kB / 48.2kB, 30.1kB/s  \n",
      "New Data Upload: 100%|██████████| 48.2kB / 48.2kB, 30.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.3kB / 42.3kB, 26.5kB/s  \n",
      "New Data Upload: 100%|██████████| 42.3kB / 42.3kB, 26.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.3kB / 42.3kB, 26.5kB/s  :03<00:00,  6.47 shards/s]\n",
      "New Data Upload: 100%|██████████| 42.3kB / 42.3kB, 26.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 37.6kB / 37.6kB, 23.5kB/s  :03<00:00,  6.47 shards/s]\n",
      "New Data Upload: 100%|██████████| 37.6kB / 37.6kB, 23.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 37.6kB / 37.6kB, 23.5kB/s  \n",
      "New Data Upload: 100%|██████████| 37.6kB / 37.6kB, 23.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 53.0kB / 53.0kB, 37.8kB/s  \n",
      "New Data Upload: 100%|██████████| 53.0kB / 53.0kB, 37.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 53.0kB / 53.0kB, 37.8kB/s  \n",
      "New Data Upload: 100%|██████████| 53.0kB / 53.0kB, 37.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 46.4kB / 46.4kB, 29.0kB/s  \n",
      "New Data Upload: 100%|██████████| 46.4kB / 46.4kB, 29.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 46.4kB / 46.4kB, 29.0kB/s  :06<00:00,  2.27 shards/s]\n",
      "New Data Upload: 100%|██████████| 46.4kB / 46.4kB, 29.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 56.6kB / 56.6kB, 35.4kB/s  :06<00:00,  2.27 shards/s]\n",
      "New Data Upload: 100%|██████████| 56.6kB / 56.6kB, 35.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 56.6kB / 56.6kB, 35.4kB/s  \n",
      "New Data Upload: 100%|██████████| 56.6kB / 56.6kB, 35.4kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:06<00:00,  2.41 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 101.12ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 82.99ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 101.37ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 82.99ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 101.37ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 58.36ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 58.36ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 72.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 90.95ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 72.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 90.95ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.61ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 102.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 87.84ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 102.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 87.84ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 111.45ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 111.45ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 69.25ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 89.94ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 89.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.74ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.74ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 12.19ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 20.42ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 170.15ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 12.19ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 20.42ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 170.15ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 20.6kB / 20.6kB, 17.2kB/s  \n",
      "New Data Upload: 100%|██████████| 20.6kB / 20.6kB, 17.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 20.6kB / 20.6kB, 17.2kB/s  02<00:42,  2.84s/ shards]\n",
      "New Data Upload: 100%|██████████| 20.6kB / 20.6kB, 17.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 24.3kB / 24.3kB, 20.2kB/s  02<00:42,  2.84s/ shards]\n",
      "New Data Upload: 100%|██████████| 24.3kB / 24.3kB, 20.2kB/s  1.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 24.3kB / 24.3kB, 20.2kB/s  \n",
      "New Data Upload: 100%|██████████| 24.3kB / 24.3kB, 20.2kB/s  1.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.9kB / 21.9kB, 18.2kB/s  \n",
      "New Data Upload: 100%|██████████| 21.9kB / 21.9kB, 18.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.6kB / 19.6kB, 16.3kB/s  \n",
      "New Data Upload: 100%|██████████| 19.6kB / 19.6kB, 16.3kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 21.9kB / 21.9kB, 18.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.6kB / 19.6kB, 16.3kB/s  \n",
      "New Data Upload: 100%|██████████| 19.6kB / 19.6kB, 16.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 23.9kB / 23.9kB, 20.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 14.1kB / 14.1kB, 11.7kB/s  \n",
      "New Data Upload: 100%|██████████| 23.9kB / 23.9kB, 20.0kB/s  \n",
      "New Data Upload: 100%|██████████| 14.1kB / 14.1kB, 11.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 17.5kB / 17.5kB, 14.6kB/s  \n",
      "New Data Upload: 100%|██████████| 17.5kB / 17.5kB, 14.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 23.9kB / 23.9kB, 20.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 14.1kB / 14.1kB, 11.7kB/s  \n",
      "New Data Upload: 100%|██████████| 23.9kB / 23.9kB, 20.0kB/s  \n",
      "New Data Upload: 100%|██████████| 14.1kB / 14.1kB, 11.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 17.5kB / 17.5kB, 14.6kB/s  \n",
      "New Data Upload: 100%|██████████| 17.5kB / 17.5kB, 14.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.2kB / 21.2kB, 17.6kB/s  \n",
      "New Data Upload: 100%|██████████| 21.2kB / 21.2kB, 17.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.2kB / 21.2kB, 17.6kB/s  \n",
      "New Data Upload: 100%|██████████| 21.2kB / 21.2kB, 17.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.2kB / 22.2kB, 18.5kB/s  \n",
      "New Data Upload: 100%|██████████| 22.2kB / 22.2kB, 18.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.2kB / 22.2kB, 18.5kB/s  02<00:01,  4.07 shards/s]\n",
      "New Data Upload: 100%|██████████| 22.2kB / 22.2kB, 18.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  02<00:01,  4.07 shards/s]\n",
      "New Data Upload: 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  \n",
      "New Data Upload: 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.6kB / 22.6kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 22.6kB / 22.6kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.6kB / 22.6kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 22.6kB / 22.6kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.9kB / 25.9kB, 18.5kB/s  \n",
      "New Data Upload: 100%|██████████| 25.9kB / 25.9kB, 18.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.9kB / 25.9kB, 18.5kB/s  \n",
      "New Data Upload: 100%|██████████| 25.9kB / 25.9kB, 18.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.3kB / 28.3kB, 17.7kB/s  \n",
      "New Data Upload: 100%|██████████| 28.3kB / 28.3kB, 17.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 28.3kB / 28.3kB, 17.7kB/s  :03<00:00,  5.69 shards/s]\n",
      "New Data Upload: 100%|██████████| 28.3kB / 28.3kB, 17.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.6kB / 18.6kB, 15.5kB/s  :03<00:00,  5.69 shards/s]\n",
      "New Data Upload: 100%|██████████| 18.6kB / 18.6kB, 15.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.6kB / 18.6kB, 15.5kB/s  \n",
      "New Data Upload: 100%|██████████| 18.6kB / 18.6kB, 15.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.2kB / 19.2kB, 16.0kB/s  \n",
      "New Data Upload: 100%|██████████| 19.2kB / 19.2kB, 16.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.2kB / 19.2kB, 16.0kB/s  \n",
      "New Data Upload: 100%|██████████| 19.2kB / 19.2kB, 16.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 23.9kB / 23.9kB, 19.9kB/s  \n",
      "New Data Upload: 100%|██████████| 23.9kB / 23.9kB, 19.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 23.9kB / 23.9kB, 19.9kB/s  :06<00:00,  2.44 shards/s]\n",
      "New Data Upload: 100%|██████████| 23.9kB / 23.9kB, 19.9kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:06<00:00,  2.52 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: precedent_qa\n",
      "  최소 split 크기: 9135, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 72.97ba/s]rds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 72.97ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.82ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.82ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 78.43ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 78.43ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 69.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 69.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 67.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.27ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.27ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 83.24ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 83.24ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 66.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 66.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.60ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.60ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.21ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.21ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 75.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 75.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.18ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  347kB /  347kB,  174kB/s  \n",
      "New Data Upload: 100%|██████████|  347kB /  347kB,  174kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.79ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  347kB /  347kB,  174kB/s  \n",
      "New Data Upload: 100%|██████████|  347kB /  347kB,  174kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.79ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  349kB /  349kB,  159kB/s  \n",
      "New Data Upload: 100%|██████████|  349kB /  349kB,  159kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  349kB /  349kB,  159kB/s  \n",
      "New Data Upload: 100%|██████████|  349kB /  349kB,  159kB/s  \n",
      "Processing Files (0 / 0): |          |  0.00B /  0.00B            /s  \n",
      "Processing Files (1 / 1): 100%|██████████|  347kB /  347kB,  158kB/s  \n",
      "New Data Upload: 100%|██████████|  347kB /  347kB,  158kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  347kB /  347kB,  158kB/s   77.38ba/s]1.26s/ shards]\n",
      "New Data Upload: 100%|██████████|  347kB /  347kB,  158kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.38ba/s]1.26s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████|  361kB /  361kB,  164kB/s  \n",
      "New Data Upload: 100%|██████████|  361kB /  361kB,  164kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  361kB /  361kB,  164kB/s  04<00:10,  1.13 shards/s]\n",
      "New Data Upload: 100%|██████████|  361kB /  361kB,  164kB/s  \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 75.32ba/s]1.13 shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 75.32ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  375kB /  375kB,  156kB/s  \n",
      "New Data Upload: 100%|██████████|  375kB /  375kB,  156kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  375kB /  375kB,  156kB/s  05<00:08,  1.34 shards/s]\n",
      "New Data Upload: 100%|██████████|  375kB /  375kB,  156kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  378kB /  378kB,  172kB/s  05<00:08,  1.34 shards/s]\n",
      "New Data Upload: 100%|██████████|  378kB /  378kB,  172kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  378kB /  378kB,  172kB/s  05<00:05,  1.68 shards/s]\n",
      "New Data Upload: 100%|██████████|  378kB /  378kB,  172kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  379kB /  379kB,  135kB/s  05<00:05,  1.68 shards/s]\n",
      "New Data Upload: 100%|██████████|  379kB /  379kB,  135kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  379kB /  379kB,  135kB/s  06<00:04,  1.91 shards/s]\n",
      "New Data Upload: 100%|██████████|  379kB /  379kB,  135kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  378kB /  378kB,  158kB/s  06<00:04,  1.91 shards/s]\n",
      "New Data Upload: 100%|██████████|  378kB /  378kB,  158kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  378kB /  378kB,  158kB/s  06<00:04,  1.72 shards/s]\n",
      "New Data Upload: 100%|██████████|  378kB /  378kB,  158kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  376kB /  376kB,  125kB/s  06<00:04,  1.72 shards/s]\n",
      "New Data Upload: 100%|██████████|  376kB /  376kB,  125kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  376kB /  376kB,  125kB/s  \n",
      "New Data Upload: 100%|██████████|  376kB /  376kB,  125kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  373kB /  373kB,  143kB/s  \n",
      "New Data Upload: 100%|██████████|  373kB /  373kB,  143kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  373kB /  373kB,  143kB/s  :06<00:02,  2.92 shards/s]\n",
      "New Data Upload: 100%|██████████|  373kB /  373kB,  143kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  376kB /  376kB,  157kB/s  :06<00:02,  2.92 shards/s]\n",
      "New Data Upload: 100%|██████████|  376kB /  376kB,  157kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  376kB /  376kB,  157kB/s  :07<00:01,  3.45 shards/s]\n",
      "New Data Upload: 100%|██████████|  376kB /  376kB,  157kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  377kB /  377kB,  157kB/s  :07<00:01,  3.45 shards/s]\n",
      "New Data Upload: 100%|██████████|  377kB /  377kB,  157kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  377kB /  377kB,  157kB/s  :07<00:01,  3.24 shards/s]\n",
      "New Data Upload: 100%|██████████|  377kB /  377kB,  157kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  375kB /  375kB,  171kB/s  :07<00:01,  3.24 shards/s]\n",
      "New Data Upload: 100%|██████████|  375kB /  375kB,  171kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  375kB /  375kB,  171kB/s  :07<00:00,  3.12 shards/s]\n",
      "New Data Upload: 100%|██████████|  375kB /  375kB,  171kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  375kB /  375kB,  170kB/s  :07<00:00,  3.12 shards/s]\n",
      "New Data Upload: 100%|██████████|  375kB /  375kB,  170kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  375kB /  375kB,  170kB/s  :07<00:00,  3.82 shards/s]\n",
      "New Data Upload: 100%|██████████|  375kB /  375kB,  170kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  374kB /  374kB,  156kB/s  :07<00:00,  3.82 shards/s]\n",
      "New Data Upload: 100%|██████████|  374kB /  374kB,  156kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  374kB /  374kB,  156kB/s  :08<00:00,  3.42 shards/s]\n",
      "New Data Upload: 100%|██████████|  374kB /  374kB,  156kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  373kB /  373kB,  169kB/s  :08<00:00,  3.42 shards/s]\n",
      "New Data Upload: 100%|██████████|  373kB /  373kB,  169kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  373kB /  373kB,  169kB/s  \n",
      "New Data Upload: 100%|██████████|  373kB /  373kB,  169kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:08<00:00,  1.87 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 137.59ba/s]ds/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 174.03ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 174.03ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 170.85ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 170.85ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.87ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.87ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 172.40ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 172.40ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 114.95ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 115.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 125.74ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 115.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 125.74ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 103.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 103.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 154.10ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 154.10ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.02ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 138.28ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 138.28ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 129.61ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 129.61ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.04ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.04ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.00ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 172.39ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.00ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 172.39ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 57.8kB / 57.8kB, 36.1kB/s  \n",
      "New Data Upload: 100%|██████████| 57.8kB / 57.8kB, 36.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.8kB / 57.8kB, 36.1kB/s  03<00:49,  3.29s/ shards]\n",
      "New Data Upload: 100%|██████████| 57.8kB / 57.8kB, 36.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  03<00:49,  3.29s/ shards]\n",
      "New Data Upload: 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  \n",
      "New Data Upload: 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.9kB / 58.9kB, 36.8kB/s  \n",
      "New Data Upload: 100%|██████████| 58.9kB / 58.9kB, 36.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.9kB / 58.9kB, 36.8kB/s  \n",
      "New Data Upload: 100%|██████████| 58.9kB / 58.9kB, 36.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  \n",
      "New Data Upload: 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  3/16 [00:03<00:11,  1.11 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 58.5kB / 58.5kB, 36.6kB/s  \n",
      "New Data Upload: 100%|██████████| 58.5kB / 58.5kB, 36.6kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  3/16 [00:03<00:11,  1.11 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 58.5kB / 58.5kB, 36.6kB/s  \n",
      "New Data Upload: 100%|██████████| 58.5kB / 58.5kB, 36.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.4kB / 57.4kB, 35.9kB/s  \n",
      "New Data Upload: 100%|██████████| 57.4kB / 57.4kB, 35.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.9kB / 57.9kB, 41.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.4kB / 57.4kB, 35.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.6kB / 57.6kB, 32.0kB/s  \n",
      "New Data Upload: 100%|██████████| 57.6kB / 57.6kB, 32.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.6kB / 57.6kB, 32.0kB/s  03<00:02,  3.24 shards/s]\n",
      "New Data Upload: 100%|██████████| 57.6kB / 57.6kB, 32.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  03<00:02,  3.24 shards/s]\n",
      "New Data Upload: 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  \n",
      "New Data Upload: 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.0kB / 57.0kB, 31.7kB/s  \n",
      "New Data Upload: 100%|██████████| 57.0kB / 57.0kB, 31.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  \n",
      "New Data Upload: 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.0kB / 57.0kB, 31.7kB/s  \n",
      "New Data Upload: 100%|██████████| 57.0kB / 57.0kB, 31.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  \n",
      "New Data Upload: 100%|██████████| 57.6kB / 57.6kB, 36.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  \n",
      "New Data Upload: 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  :03<00:00,  5.77 shards/s]\n",
      "New Data Upload: 100%|██████████| 57.9kB / 57.9kB, 36.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.8kB / 58.8kB, 36.8kB/s  :03<00:00,  5.77 shards/s]\n",
      "New Data Upload: 100%|██████████| 58.8kB / 58.8kB, 36.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.8kB / 58.8kB, 36.8kB/s  \n",
      "New Data Upload: 100%|██████████| 58.8kB / 58.8kB, 36.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.8kB / 57.8kB, 32.1kB/s  \n",
      "New Data Upload: 100%|██████████| 57.8kB / 57.8kB, 32.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.8kB / 57.8kB, 32.1kB/s  \n",
      "New Data Upload: 100%|██████████| 57.8kB / 57.8kB, 32.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  \n",
      "New Data Upload: 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  :03<00:00,  7.21 shards/s]\n",
      "New Data Upload: 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  :03<00:00,  7.21 shards/s]\n",
      "New Data Upload: 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  \n",
      "New Data Upload: 100%|██████████| 58.1kB / 58.1kB, 32.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.5kB / 57.5kB, 31.9kB/s  \n",
      "New Data Upload: 100%|██████████| 57.5kB / 57.5kB, 31.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 57.5kB / 57.5kB, 31.9kB/s  \n",
      "New Data Upload: 100%|██████████| 57.5kB / 57.5kB, 31.9kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:04<00:00,  3.27 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: precedent_summary\n",
      "  최소 split 크기: 392, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 154.87ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 154.87ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 170.20ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 157.73ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 157.73ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.61ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.61ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 167.50ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 167.50ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 160.66ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 160.66ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 75.42ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 172.61ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 152.27ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.87ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 152.27ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 143.87ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 117.03ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 138.36ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 117.03ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 138.36ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 22.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 22.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 18.95ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 18.95ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 147.31ba/s]\n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  \n",
      "New Data Upload: 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  \n",
      "New Data Upload: 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  03<00:45,  3.05s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  \n",
      "New Data Upload: 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  \n",
      "New Data Upload: 100%|██████████| 26.7kB / 26.7kB, 19.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  03<00:45,  3.05s/ shards]\n",
      "New Data Upload: 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.4kB / 26.4kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 26.4kB / 26.4kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.4kB / 26.4kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 26.4kB / 26.4kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  03<00:05,  2.06 shards/s]\n",
      "New Data Upload: 100%|██████████| 26.3kB / 26.3kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.0kB / 26.0kB, 16.3kB/s  03<00:05,  2.06 shards/s]\n",
      "New Data Upload: 100%|██████████| 26.0kB / 26.0kB, 16.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.0kB / 26.0kB, 16.3kB/s  \n",
      "New Data Upload: 100%|██████████| 26.0kB / 26.0kB, 16.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.8kB / 25.8kB, 18.4kB/s  \n",
      "New Data Upload: 100%|██████████| 25.8kB / 25.8kB, 18.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 27.1kB / 27.1kB, 19.4kB/s  03<00:03,  2.88 shards/s]\n",
      "New Data Upload: 100%|██████████| 27.1kB / 27.1kB, 19.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.8kB / 25.8kB, 18.4kB/s  \n",
      "New Data Upload: 100%|██████████| 25.8kB / 25.8kB, 18.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 27.1kB / 27.1kB, 19.4kB/s  03<00:03,  2.88 shards/s]\n",
      "New Data Upload: 100%|██████████| 27.1kB / 27.1kB, 19.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.5kB / 26.5kB, 18.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  \n",
      "New Data Upload: 100%|██████████| 26.5kB / 26.5kB, 18.9kB/s  \n",
      "New Data Upload: 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  \n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  \n",
      "New Data Upload: 100%|██████████| 26.5kB / 26.5kB, 18.9kB/s  \n",
      "New Data Upload: 100%|██████████| 25.6kB / 25.6kB, 18.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "New Data Upload: 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "New Data Upload: 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "New Data Upload: 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "New Data Upload: 100%|██████████| 26.4kB / 26.4kB, 18.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.8kB / 25.8kB, 18.5kB/s  \n",
      "New Data Upload: 100%|██████████| 25.8kB / 25.8kB, 18.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.8kB / 25.8kB, 18.5kB/s  \n",
      "New Data Upload: 100%|██████████| 25.8kB / 25.8kB, 18.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.0kB / 26.0kB, 18.6kB/s  \n",
      "New Data Upload: 100%|██████████| 26.0kB / 26.0kB, 18.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.0kB / 26.0kB, 18.6kB/s  \n",
      "New Data Upload: 100%|██████████| 26.0kB / 26.0kB, 18.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.2kB / 26.2kB, 16.4kB/s  \n",
      "New Data Upload: 100%|██████████| 26.2kB / 26.2kB, 16.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 26.2kB / 26.2kB, 16.4kB/s  :03<00:00,  7.87 shards/s]\n",
      "New Data Upload: 100%|██████████| 26.2kB / 26.2kB, 16.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.9kB / 25.9kB, 16.2kB/s  :03<00:00,  7.87 shards/s]\n",
      "New Data Upload: 100%|██████████| 25.9kB / 25.9kB, 16.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.9kB / 25.9kB, 16.2kB/s  \n",
      "New Data Upload: 100%|██████████| 25.9kB / 25.9kB, 16.2kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:03<00:00,  4.15 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]9.31ba/s]ds/s]\n",
      "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]9.31ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 126.29ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 108.75ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.69ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 126.29ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 108.75ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.69ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.69ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 151.67ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.69ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 151.67ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 127.97ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 127.97ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 110.05ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 110.05ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 42.11ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 42.11ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 42.85ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 86.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 86.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 145.52ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 105.98ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 105.98ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.43ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 26.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 161.25ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.43ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 26.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 161.25ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 11.3kB / 11.3kB, 9.43kB/s  \n",
      "New Data Upload: 100%|██████████| 11.3kB / 11.3kB, 9.43kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.5kB / 11.5kB, 9.55kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.4kB / 11.4kB, 9.47kB/s  \n",
      "New Data Upload: 100%|██████████| 11.5kB / 11.5kB, 9.55kB/s  1/16 [00:02<00:42,  2.82s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 11.3kB / 11.3kB, 9.43kB/s  \n",
      "New Data Upload: 100%|██████████| 11.3kB / 11.3kB, 9.43kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.5kB / 11.5kB, 9.55kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.4kB / 11.4kB, 9.47kB/s  \n",
      "New Data Upload: 100%|██████████| 11.5kB / 11.5kB, 9.55kB/s  1/16 [00:02<00:42,  2.82s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 11.4kB / 11.4kB, 9.49kB/s  \n",
      "New Data Upload: 100%|██████████| 11.4kB / 11.4kB, 9.47kB/s  \n",
      "New Data Upload: 100%|██████████| 11.4kB / 11.4kB, 9.49kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.1kB / 11.1kB, 9.28kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 11.4kB / 11.4kB, 9.47kB/s  \n",
      "New Data Upload: 100%|██████████| 11.4kB / 11.4kB, 9.49kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.1kB / 11.1kB, 9.28kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 12.0kB / 12.0kB, 9.98kB/s  \n",
      "New Data Upload: 100%|██████████| 11.1kB / 11.1kB, 9.28kB/s  \n",
      "New Data Upload: 100%|██████████| 12.0kB / 12.0kB, 9.98kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 12.0kB / 12.0kB, 9.98kB/s  \n",
      "New Data Upload: 100%|██████████| 11.1kB / 11.1kB, 9.28kB/s  \n",
      "New Data Upload: 100%|██████████| 12.0kB / 12.0kB, 9.98kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.2kB / 11.2kB, 9.33kB/s  \n",
      "New Data Upload: 100%|██████████| 11.2kB / 11.2kB, 9.33kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.2kB / 11.2kB, 9.33kB/s  \n",
      "New Data Upload: 100%|██████████| 11.2kB / 11.2kB, 9.33kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.9kB / 10.9kB, 9.12kB/s  \n",
      "New Data Upload: 100%|██████████| 10.9kB / 10.9kB, 9.12kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.9kB / 10.9kB, 9.12kB/s  \n",
      "New Data Upload: 100%|██████████| 10.9kB / 10.9kB, 9.12kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.9kB / 10.9kB, 9.04kB/s  \n",
      "New Data Upload: 100%|██████████| 10.9kB / 10.9kB, 9.04kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.3kB / 11.3kB, 8.06kB/s  \n",
      "New Data Upload: 100%|██████████| 11.3kB / 11.3kB, 8.06kB/s  9/16 [00:03<00:01,  3.99 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 10.9kB / 10.9kB, 9.04kB/s  \n",
      "New Data Upload: 100%|██████████| 10.9kB / 10.9kB, 9.04kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.3kB / 11.3kB, 8.06kB/s  \n",
      "New Data Upload: 100%|██████████| 11.3kB / 11.3kB, 8.06kB/s  9/16 [00:03<00:01,  3.99 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 11.0kB / 11.0kB, 7.87kB/s  \n",
      "New Data Upload: 100%|██████████| 11.0kB / 11.0kB, 7.87kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.6kB / 11.6kB, 9.65kB/s  \n",
      "New Data Upload: 100%|██████████| 11.6kB / 11.6kB, 9.65kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.0kB / 11.0kB, 7.87kB/s  \n",
      "New Data Upload: 100%|██████████| 11.0kB / 11.0kB, 7.87kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.6kB / 11.6kB, 9.65kB/s  \n",
      "New Data Upload: 100%|██████████| 11.6kB / 11.6kB, 9.65kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 12.0kB / 12.0kB, 9.96kB/s  \n",
      "New Data Upload: 100%|██████████| 12.0kB / 12.0kB, 9.96kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 12.0kB / 12.0kB, 9.96kB/s  :03<00:00,  5.85 shards/s]\n",
      "New Data Upload: 100%|██████████| 12.0kB / 12.0kB, 9.96kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.2kB / 11.2kB, 8.00kB/s  :03<00:00,  5.85 shards/s]\n",
      "New Data Upload: 100%|██████████| 11.2kB / 11.2kB, 8.00kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.2kB / 11.2kB, 8.00kB/s  \n",
      "New Data Upload: 100%|██████████| 11.2kB / 11.2kB, 8.00kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.0kB / 11.0kB, 7.88kB/s  \n",
      "New Data Upload: 100%|██████████| 11.0kB / 11.0kB, 7.88kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.0kB / 11.0kB, 7.88kB/s  \n",
      "New Data Upload: 100%|██████████| 11.0kB / 11.0kB, 7.88kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.9kB / 10.9kB, 7.81kB/s  \n",
      "New Data Upload: 100%|██████████| 10.9kB / 10.9kB, 7.81kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.9kB / 10.9kB, 7.81kB/s  :04<00:00,  4.60 shards/s]\n",
      "New Data Upload: 100%|██████████| 10.9kB / 10.9kB, 7.81kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:04<00:00,  3.58 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: statute_qa\n",
      "  최소 split 크기: 2, num_proc: 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 191.98ba/s]/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 191.98ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 189.38ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 189.38ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 8.78kB / 8.78kB, 7.32kB/s  \n",
      "New Data Upload: 100%|██████████| 8.78kB / 8.78kB, 7.32kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.78kB / 8.78kB, 7.32kB/s  <00:02,  2.54s/ shards]\n",
      "New Data Upload: 100%|██████████| 8.78kB / 8.78kB, 7.32kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.23kB / 8.23kB, 5.88kB/s  <00:02,  2.54s/ shards]\n",
      "New Data Upload: 100%|██████████| 8.23kB / 8.23kB, 5.88kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.23kB / 8.23kB, 5.88kB/s  \n",
      "New Data Upload: 100%|██████████| 8.23kB / 8.23kB, 5.88kB/s  \n",
      "Uploading the dataset shards (num_proc=2): 100%|██████████| 2/2 [00:02<00:00,  1.37s/ shards]\n",
      "Uploading the dataset shards (num_proc=2): 100%|██████████| 2/2 [00:02<00:00,  1.37s/ shards]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 193.91ba/s]/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 230.11ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 193.91ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 230.11ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 7.74kB / 7.74kB, 6.45kB/s  \n",
      "New Data Upload: 100%|██████████| 7.74kB / 7.74kB, 6.45kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 7.87kB / 7.87kB, 6.56kB/s  \n",
      "New Data Upload: 100%|██████████| 7.87kB / 7.87kB, 6.56kB/s  /2 [00:02<00:02,  2.35s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 7.74kB / 7.74kB, 6.45kB/s  \n",
      "New Data Upload: 100%|██████████| 7.74kB / 7.74kB, 6.45kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 7.87kB / 7.87kB, 6.56kB/s  \n",
      "New Data Upload: 100%|██████████| 7.87kB / 7.87kB, 6.56kB/s  /2 [00:02<00:02,  2.35s/ shards]\n",
      "Uploading the dataset shards (num_proc=2): 100%|██████████| 2/2 [00:02<00:00,  1.25s/ shards]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: trial_decision_qa\n",
      "  최소 split 크기: 279, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.57ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 175.87ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 175.87ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 159.72ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 159.72ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 155.28ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.26ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.26ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 132.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 132.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 117.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 117.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 155.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 155.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.52ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 178.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 134.52ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 178.18ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 103.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 156.54ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 103.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 96.86ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 171.64ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 96.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 171.64ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 27.28ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 172.31ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 27.28ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 172.31ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "New Data Upload: 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  02<00:43,  2.88s/ shards]\n",
      "New Data Upload: 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  02<00:43,  2.88s/ shards]\n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  03<00:10,  1.25 shards/s]\n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  03<00:10,  1.25 shards/s]\n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 11.4kB/s  \n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 11.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 11.4kB/s  \n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 11.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.6kB / 15.6kB, 11.2kB/s  \n",
      "New Data Upload: 100%|██████████| 15.6kB / 15.6kB, 11.2kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 15.6kB / 15.6kB, 11.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "New Data Upload: 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "New Data Upload: 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "New Data Upload: 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.7kB / 15.7kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.1kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.1kB/s  :03<00:00,  6.02 shards/s]\n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 11.3kB/s  :03<00:00,  6.02 shards/s]\n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.9kB / 15.9kB, 13.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  :03<00:00,  6.29 shards/s]\n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 11.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  :03<00:00,  6.29 shards/s]\n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "New Data Upload: 100%|██████████| 15.8kB / 15.8kB, 13.2kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:04<00:00,  3.95 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.24ba/s]rds/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 77.24ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.15ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 107.80ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 110.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 158.07ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 174.58ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.15ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 107.80ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 110.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 158.07ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 174.58ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 61.23ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 71.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 85.90ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 102.47ba/s]\n",
      "\n",
      "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 85.90ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.93ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 76.93ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 12.15ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.90ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 12.15ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 13.90ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 126.27ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 230.22ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 37.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 230.22ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 9.07kB / 9.07kB, 7.56kB/s  \n",
      "New Data Upload: 100%|██████████| 9.07kB / 9.07kB, 7.56kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.07kB / 9.07kB, 7.56kB/s  02<00:42,  2.86s/ shards]\n",
      "New Data Upload: 100%|██████████| 9.07kB / 9.07kB, 7.56kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.96kB / 8.96kB, 7.47kB/s  02<00:42,  2.86s/ shards]\n",
      "New Data Upload: 100%|██████████| 8.96kB / 8.96kB, 7.47kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.96kB / 8.96kB, 7.47kB/s  \n",
      "New Data Upload: 100%|██████████| 8.96kB / 8.96kB, 7.47kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.00kB / 9.00kB, 7.50kB/s  \n",
      "New Data Upload: 100%|██████████| 9.00kB / 9.00kB, 7.50kB/s  .87kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.05kB / 9.05kB, 7.55kB/s  \n",
      "New Data Upload: 100%|██████████| 9.05kB / 9.05kB, 7.55kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.00kB / 9.00kB, 7.50kB/s  \n",
      "New Data Upload: 100%|██████████| 9.00kB / 9.00kB, 7.50kB/s  .87kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.05kB / 9.05kB, 7.55kB/s  \n",
      "New Data Upload: 100%|██████████| 9.05kB / 9.05kB, 7.55kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.02kB / 9.02kB, 7.52kB/s  \n",
      "New Data Upload: 100%|██████████| 9.02kB / 9.02kB, 7.52kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.02kB / 9.02kB, 7.52kB/s  \n",
      "New Data Upload: 100%|██████████| 9.02kB / 9.02kB, 7.52kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.13kB / 9.13kB, 6.52kB/s  \n",
      "New Data Upload: 100%|██████████| 9.13kB / 9.13kB, 6.52kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.00kB / 9.00kB, 6.43kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.04kB / 9.04kB, 6.47kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.10kB / 9.10kB, 6.50kB/s  03<00:03,  2.60 shards/s]\n",
      "New Data Upload: 100%|██████████| 9.04kB / 9.04kB, 6.47kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.13kB / 9.13kB, 6.52kB/s  \n",
      "New Data Upload: 100%|██████████| 9.13kB / 9.13kB, 6.52kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.00kB / 9.00kB, 6.43kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.04kB / 9.04kB, 6.47kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.10kB / 9.10kB, 6.50kB/s  03<00:03,  2.60 shards/s]\n",
      "New Data Upload: 100%|██████████| 9.04kB / 9.04kB, 6.47kB/s  \n",
      "New Data Upload: 100%|██████████| 9.00kB / 9.00kB, 6.43kB/s  \n",
      "New Data Upload: 100%|██████████| 9.10kB / 9.10kB, 6.50kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.04kB / 9.04kB, 6.45kB/s  \n",
      "New Data Upload: 100%|██████████| 9.04kB / 9.04kB, 6.45kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.08kB / 9.08kB, 6.49kB/s  \n",
      "New Data Upload: 100%|██████████| 9.08kB / 9.08kB, 6.49kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 9.10kB / 9.10kB, 6.50kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.04kB / 9.04kB, 6.45kB/s  \n",
      "New Data Upload: 100%|██████████| 9.04kB / 9.04kB, 6.45kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.08kB / 9.08kB, 6.49kB/s  \n",
      "New Data Upload: 100%|██████████| 9.08kB / 9.08kB, 6.49kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.04kB / 9.04kB, 6.46kB/s  \n",
      "New Data Upload: 100%|██████████| 9.04kB / 9.04kB, 6.46kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.04kB / 9.04kB, 6.46kB/s  \n",
      "New Data Upload: 100%|██████████| 9.04kB / 9.04kB, 6.46kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.91kB / 8.91kB, 7.43kB/s  \n",
      "New Data Upload: 100%|██████████| 8.91kB / 8.91kB, 7.43kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.91kB / 8.91kB, 7.43kB/s  :03<00:00,  6.70 shards/s]\n",
      "New Data Upload: 100%|██████████| 8.91kB / 8.91kB, 7.43kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.11kB / 9.11kB, 6.51kB/s  :03<00:00,  6.70 shards/s]\n",
      "New Data Upload: 100%|██████████| 9.11kB / 9.11kB, 6.51kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.09kB / 9.09kB, 6.49kB/s  \n",
      "New Data Upload: 100%|██████████| 9.09kB / 9.09kB, 6.49kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.11kB / 9.11kB, 6.51kB/s  \n",
      "New Data Upload: 100%|██████████| 9.11kB / 9.11kB, 6.51kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.09kB / 9.09kB, 6.49kB/s  \n",
      "New Data Upload: 100%|██████████| 9.09kB / 9.09kB, 6.49kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.87kB / 8.87kB, 6.33kB/s  \n",
      "New Data Upload: 100%|██████████| 8.87kB / 8.87kB, 6.33kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 8.87kB / 8.87kB, 6.33kB/s  \n",
      "New Data Upload: 100%|██████████| 8.87kB / 8.87kB, 6.33kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:03<00:00,  4.56 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: trial_decision_summary\n",
      "  최소 split 크기: 140, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 126.70ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 126.70ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 147.38ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 147.38ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 125.00ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 125.00ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 145.02ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 145.02ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 136.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 136.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 145.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 145.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 120.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 120.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 118.29ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 118.29ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.95ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.95ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 128.47ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 128.47ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.78ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.51ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 141.51ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.12ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.12ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.16ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 122.16ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 99.76ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 99.76ba/s]\n",
      "Processing Files (0 / 0): |          |  0.00B /  0.00B            \n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 98.35ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████|  447kB /  447kB,  172kB/s  \n",
      "New Data Upload: 100%|██████████|  447kB /  447kB,  172kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  447kB /  447kB,  172kB/s  04<01:06,  4.45s/ shards]\n",
      "New Data Upload: 100%|██████████|  447kB /  447kB,  172kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  433kB /  433kB,  155kB/s  04<01:06,  4.45s/ shards]\n",
      "New Data Upload: 100%|██████████|  433kB /  433kB,  155kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  433kB /  433kB,  155kB/s  04<00:29,  2.09s/ shards]\n",
      "New Data Upload: 100%|██████████|  433kB /  433kB,  155kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  470kB /  470kB,  147kB/s  04<00:29,  2.09s/ shards]\n",
      "New Data Upload: 100%|██████████|  470kB /  470kB,  147kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  470kB /  470kB,  147kB/s  05<00:16,  1.25s/ shards]\n",
      "New Data Upload: 100%|██████████|  470kB /  470kB,  147kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  491kB /  491kB,  189kB/s  05<00:16,  1.25s/ shards]\n",
      "New Data Upload: 100%|██████████|  491kB /  491kB,  189kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  491kB /  491kB,  189kB/s  05<00:09,  1.26 shards/s]\n",
      "New Data Upload: 100%|██████████|  491kB /  491kB,  189kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  569kB /  569kB,  178kB/s  05<00:09,  1.26 shards/s]\n",
      "New Data Upload: 100%|██████████|  569kB /  569kB,  178kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  569kB /  569kB,  178kB/s  \n",
      "New Data Upload: 100%|██████████|  569kB /  569kB,  178kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  527kB /  527kB,  203kB/s  \n",
      "New Data Upload: 100%|██████████|  527kB /  527kB,  203kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  527kB /  527kB,  219kB/s  05<00:04,  2.45 shards/s]\n",
      "New Data Upload: 100%|██████████|  527kB /  527kB,  219kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  527kB /  527kB,  203kB/s  \n",
      "New Data Upload: 100%|██████████|  527kB /  527kB,  203kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  527kB /  527kB,  219kB/s  05<00:04,  2.45 shards/s]\n",
      "New Data Upload: 100%|██████████|  527kB /  527kB,  219kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  498kB /  498kB,  166kB/s  \n",
      "New Data Upload: 100%|██████████|  498kB /  498kB,  166kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  450kB /  450kB,  187kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  498kB /  498kB,  166kB/s  \n",
      "New Data Upload: 100%|██████████|  498kB /  498kB,  166kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  450kB /  450kB,  187kB/s  \n",
      "New Data Upload: 100%|██████████|  450kB /  450kB,  187kB/s  220kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  533kB /  533kB,  205kB/s  \n",
      "New Data Upload: 100%|██████████|  450kB /  450kB,  187kB/s  220kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  533kB /  533kB,  205kB/s  \n",
      "New Data Upload: 100%|██████████|  533kB /  533kB,  205kB/s  \n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████|  479kB /  479kB,  160kB/s  \n",
      "New Data Upload: 100%|██████████|  479kB /  479kB,  160kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  479kB /  479kB,  160kB/s  :05<00:00,  6.37 shards/s]\n",
      "New Data Upload: 100%|██████████|  479kB /  479kB,  160kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  440kB /  440kB,  200kB/s  :05<00:00,  6.37 shards/s]\n",
      "New Data Upload: 100%|██████████|  440kB /  440kB,  200kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  440kB /  440kB,  200kB/s  \n",
      "New Data Upload: 100%|██████████|  440kB /  440kB,  200kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  428kB /  428kB,  165kB/s  \n",
      "New Data Upload: 100%|██████████|  428kB /  428kB,  165kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  428kB /  428kB,  165kB/s  \n",
      "New Data Upload: 100%|██████████|  428kB /  428kB,  165kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  498kB /  498kB,  208kB/s  \n",
      "New Data Upload: 100%|██████████|  498kB /  498kB,  208kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  498kB /  498kB,  208kB/s  :06<00:00,  5.99 shards/s]\n",
      "New Data Upload: 100%|██████████|  498kB /  498kB,  208kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  496kB /  496kB,  155kB/s  :06<00:00,  5.99 shards/s]\n",
      "New Data Upload: 100%|██████████|  496kB /  496kB,  155kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  496kB /  496kB,  155kB/s  \n",
      "New Data Upload: 100%|██████████|  496kB /  496kB,  155kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  563kB /  563kB,  148kB/s  \n",
      "New Data Upload: 100%|██████████|  563kB /  563kB,  148kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████|  563kB /  563kB,  148kB/s  :07<00:00,  3.52 shards/s]\n",
      "New Data Upload: 100%|██████████|  563kB /  563kB,  148kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:07<00:00,  2.13 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 150.52ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 241.05ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 150.52ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 241.05ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 267.66ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 148.63ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 148.63ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 261.54ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 261.54ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 219.01ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 190.54ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 190.54ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 202.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 202.94ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 202.25ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 202.25ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 70.62ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 80.80ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 156.21ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 148.23ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 156.21ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 148.23ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 167.28ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 167.28ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 35.04ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 313.01ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 35.04ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 313.01ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 44.0kB / 44.0kB, 36.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 59.6kB / 59.6kB, 37.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 59.6kB / 59.6kB, 37.2kB/s  \n",
      "New Data Upload: 100%|██████████| 59.6kB / 59.6kB, 37.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 61.8kB / 61.8kB, 38.6kB/s  03<00:49,  3.27s/ shards]\n",
      "New Data Upload: 100%|██████████| 61.8kB / 61.8kB, 38.6kB/s  0.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 70.3kB / 70.3kB, 50.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 61.8kB / 61.8kB, 38.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 63.5kB / 63.5kB, 35.3kB/s  \n",
      "New Data Upload: 100%|██████████| 63.5kB / 63.5kB, 35.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 53.7kB / 53.7kB, 29.9kB/s  \n",
      "New Data Upload: 100%|██████████| 53.7kB / 53.7kB, 29.9kB/s  3/16 [00:03<00:11,  1.11 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 63.5kB / 63.5kB, 35.3kB/s  \n",
      "New Data Upload: 100%|██████████| 63.5kB / 63.5kB, 35.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 53.7kB / 53.7kB, 29.9kB/s  \n",
      "New Data Upload: 100%|██████████| 53.7kB / 53.7kB, 29.9kB/s  3/16 [00:03<00:11,  1.11 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 54.8kB / 54.8kB, 30.4kB/s  \n",
      "New Data Upload: 100%|██████████| 54.8kB / 54.8kB, 30.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 54.8kB / 54.8kB, 30.4kB/s  \n",
      "New Data Upload: 100%|██████████| 54.8kB / 54.8kB, 30.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 56.8kB / 56.8kB, 35.5kB/s  \n",
      "New Data Upload: 100%|██████████| 56.8kB / 56.8kB, 35.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 70.3kB / 70.3kB, 43.9kB/s  \n",
      "New Data Upload: 100%|██████████| 70.3kB / 70.3kB, 43.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 56.8kB / 56.8kB, 35.5kB/s  \n",
      "New Data Upload: 100%|██████████| 56.8kB / 56.8kB, 35.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 70.3kB / 70.3kB, 43.9kB/s  \n",
      "New Data Upload: 100%|██████████| 70.3kB / 70.3kB, 43.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 55.4kB / 55.4kB, 30.8kB/s  \n",
      "New Data Upload: 100%|██████████| 55.4kB / 55.4kB, 30.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.6kB / 58.6kB, 32.6kB/s  \n",
      "New Data Upload: 100%|██████████| 58.6kB / 58.6kB, 32.6kB/s  8/16 [00:03<00:02,  3.69 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 55.4kB / 55.4kB, 30.8kB/s  \n",
      "New Data Upload: 100%|██████████| 55.4kB / 55.4kB, 30.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 58.6kB / 58.6kB, 32.6kB/s  \n",
      "New Data Upload: 100%|██████████| 58.6kB / 58.6kB, 32.6kB/s  8/16 [00:03<00:02,  3.69 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 61.2kB / 61.2kB, 34.0kB/s  \n",
      "New Data Upload: 100%|██████████| 61.2kB / 61.2kB, 34.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 46.5kB / 46.5kB, 25.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 59.2kB / 59.2kB, 32.9kB/s  \n",
      "New Data Upload: 100%|██████████| 46.5kB / 46.5kB, 25.8kB/s  \n",
      "New Data Upload: 100%|██████████| 59.2kB / 59.2kB, 32.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 61.2kB / 61.2kB, 34.0kB/s  \n",
      "New Data Upload: 100%|██████████| 61.2kB / 61.2kB, 34.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 46.5kB / 46.5kB, 25.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 59.2kB / 59.2kB, 32.9kB/s  \n",
      "New Data Upload: 100%|██████████| 46.5kB / 46.5kB, 25.8kB/s  \n",
      "New Data Upload: 100%|██████████| 59.2kB / 59.2kB, 32.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 44.0kB / 44.0kB, 27.5kB/s  \n",
      "New Data Upload: 100%|██████████| 44.0kB / 44.0kB, 27.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 44.0kB / 44.0kB, 27.5kB/s  \n",
      "New Data Upload: 100%|██████████| 44.0kB / 44.0kB, 27.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 52.1kB / 52.1kB, 29.0kB/s  \n",
      "New Data Upload: 100%|██████████| 52.1kB / 52.1kB, 29.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 52.1kB / 52.1kB, 29.0kB/s  :03<00:00,  7.19 shards/s]\n",
      "New Data Upload: 100%|██████████| 52.1kB / 52.1kB, 29.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 73.0kB / 73.0kB, 40.6kB/s  :03<00:00,  7.19 shards/s]\n",
      "New Data Upload: 100%|██████████| 73.0kB / 73.0kB, 40.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 73.0kB / 73.0kB, 40.6kB/s  \n",
      "New Data Upload: 100%|██████████| 73.0kB / 73.0kB, 40.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 89.8kB / 89.8kB, 49.9kB/s  \n",
      "New Data Upload: 100%|██████████| 89.8kB / 89.8kB, 49.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 89.8kB / 89.8kB, 49.9kB/s  \n",
      "New Data Upload: 100%|██████████| 89.8kB / 89.8kB, 49.9kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:04<00:00,  3.36 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: interpretation_qa\n",
      "  최소 split 크기: 38, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 218.50ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 218.50ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 119.40ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 136.70ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 119.40ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 136.70ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 146.76ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 146.76ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 137.75ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 254.63ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 137.75ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 254.63ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 191.99ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 191.99ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 146.42ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 261.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 232.41ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 146.42ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 261.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 232.41ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 84.13ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 226.41ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 84.13ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 226.41ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 74.43ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 21.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 21.56ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 27.17ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 259.69ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 27.17ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 259.69ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 36.5kB / 36.5kB, 26.0kB/s  \n",
      "New Data Upload: 100%|██████████| 36.5kB / 36.5kB, 26.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.6kB / 42.6kB, 30.5kB/s  \n",
      "New Data Upload: 100%|██████████| 42.6kB / 42.6kB, 30.5kB/s  1/16 [00:03<00:46,  3.08s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 36.5kB / 36.5kB, 26.0kB/s  \n",
      "New Data Upload: 100%|██████████| 36.5kB / 36.5kB, 26.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.6kB / 42.6kB, 30.5kB/s  \n",
      "New Data Upload: 100%|██████████| 42.6kB / 42.6kB, 30.5kB/s  1/16 [00:03<00:46,  3.08s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 39.1kB / 39.1kB, 27.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 40.7kB / 40.7kB, 29.1kB/s  \n",
      "New Data Upload: 100%|██████████| 39.1kB / 39.1kB, 27.9kB/s  \n",
      "New Data Upload: 100%|██████████| 40.7kB / 40.7kB, 29.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 39.1kB / 39.1kB, 27.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 40.7kB / 40.7kB, 29.1kB/s  \n",
      "New Data Upload: 100%|██████████| 39.1kB / 39.1kB, 27.9kB/s  \n",
      "New Data Upload: 100%|██████████| 40.7kB / 40.7kB, 29.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.9kB / 42.9kB, 30.6kB/s  \n",
      "New Data Upload: 100%|██████████| 42.9kB / 42.9kB, 30.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 39.7kB / 39.7kB, 24.8kB/s  03<00:05,  1.98 shards/s]\n",
      "New Data Upload: 100%|██████████| 39.7kB / 39.7kB, 24.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 38.0kB / 38.0kB, 23.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.9kB / 42.9kB, 30.6kB/s  \n",
      "New Data Upload: 100%|██████████| 42.9kB / 42.9kB, 30.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 39.7kB / 39.7kB, 24.8kB/s  03<00:05,  1.98 shards/s]\n",
      "New Data Upload: 100%|██████████| 39.7kB / 39.7kB, 24.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 38.0kB / 38.0kB, 23.7kB/s  \n",
      "New Data Upload: 100%|██████████| 38.0kB / 38.0kB, 23.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 41.6kB / 41.6kB, 26.0kB/s  \n",
      "New Data Upload: 100%|██████████| 41.6kB / 41.6kB, 26.0kB/s  \n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 41.6kB / 41.6kB, 26.0kB/s  \n",
      "New Data Upload: 100%|██████████| 41.6kB / 41.6kB, 26.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 38.7kB / 38.7kB, 24.2kB/s  \n",
      "New Data Upload: 100%|██████████| 38.7kB / 38.7kB, 24.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 38.7kB / 38.7kB, 24.2kB/s  \n",
      "New Data Upload: 100%|██████████| 38.7kB / 38.7kB, 24.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 34.9kB / 34.9kB, 21.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 31.6kB / 31.6kB, 19.7kB/s  \n",
      "New Data Upload: 100%|██████████| 34.9kB / 34.9kB, 21.8kB/s  \n",
      "New Data Upload: 100%|██████████| 31.6kB / 31.6kB, 19.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.3kB / 42.3kB, 26.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 32.9kB / 32.9kB, 20.6kB/s  :03<00:01,  4.67 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 34.9kB / 34.9kB, 21.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 31.6kB / 31.6kB, 19.7kB/s  \n",
      "New Data Upload: 100%|██████████| 34.9kB / 34.9kB, 21.8kB/s  \n",
      "New Data Upload: 100%|██████████| 31.6kB / 31.6kB, 19.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 42.3kB / 42.3kB, 26.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 32.9kB / 32.9kB, 20.6kB/s  :03<00:01,  4.67 shards/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 42.5kB / 42.5kB, 26.5kB/s  \n",
      "New Data Upload: 100%|██████████| 42.3kB / 42.3kB, 26.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 40.2kB / 40.2kB, 25.1kB/s  \n",
      "New Data Upload: 100%|██████████| 32.9kB / 32.9kB, 20.6kB/s  \n",
      "New Data Upload: 100%|██████████| 40.2kB / 40.2kB, 25.1kB/s  \n",
      "New Data Upload: 100%|██████████| 42.5kB / 42.5kB, 26.5kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 42.3kB / 42.3kB, 26.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 40.2kB / 40.2kB, 25.1kB/s  \n",
      "New Data Upload: 100%|██████████| 32.9kB / 32.9kB, 20.6kB/s  \n",
      "New Data Upload: 100%|██████████| 40.2kB / 40.2kB, 25.1kB/s  \n",
      "New Data Upload: 100%|██████████| 42.5kB / 42.5kB, 26.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 39.5kB / 39.5kB, 24.7kB/s  \n",
      "New Data Upload: 100%|██████████| 39.5kB / 39.5kB, 24.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 39.5kB / 39.5kB, 24.7kB/s  \n",
      "New Data Upload: 100%|██████████| 39.5kB / 39.5kB, 24.7kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:03<00:00,  4.30 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 213.23ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 213.23ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 72.44ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 72.44ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.60ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 53.24ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 46.98ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 53.24ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 46.98ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 221.92ba/s]\n",
      "\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 28.91ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 73.15ba/s]\n",
      "\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 38.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 38.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 41.65ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.89ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.81ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 65.89ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.81ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.35ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 24.52ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 26.37ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.35ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 24.52ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 26.37ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 149.38ba/s]\n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 11.9kB / 11.9kB, 8.53kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.9kB / 11.9kB, 8.53kB/s  \n",
      "New Data Upload: 100%|██████████| 11.9kB / 11.9kB, 8.53kB/s  .99kB/s  \n",
      "New Data Upload: 100%|██████████| 11.9kB / 11.9kB, 8.53kB/s  .99kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.4kB / 21.4kB, 15.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 13.6kB / 13.6kB, 9.69kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.0kB / 21.0kB, 15.0kB/s  \n",
      "Uploading the dataset shards (num_proc=16):   6%|▋         | 1/16 [00:03<00:47,  3.16s/ shards]\n",
      "New Data Upload: 100%|██████████| 11.8kB / 11.8kB, 9.83kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 13.6kB / 13.6kB, 9.69kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.0kB / 21.0kB, 15.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.88kB / 9.88kB, 7.06kB/s  03<00:47,  3.16s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 13.2kB / 13.2kB, 9.44kB/s  \n",
      "New Data Upload: 100%|██████████| 21.4kB / 21.4kB, 15.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.88kB / 9.88kB, 7.06kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 13.2kB / 13.2kB, 9.44kB/s  \n",
      "New Data Upload: 100%|██████████| 21.4kB / 21.4kB, 15.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.7kB / 22.7kB, 16.2kB/s  \n",
      "New Data Upload: 100%|██████████| 9.88kB / 9.88kB, 7.06kB/s  .16kB/s  \n",
      "New Data Upload: 100%|██████████| 13.2kB / 13.2kB, 9.44kB/s  \n",
      "New Data Upload: 100%|██████████| 13.6kB / 13.6kB, 9.69kB/s  \n",
      "New Data Upload: 100%|██████████| 21.0kB / 21.0kB, 15.0kB/s  \n",
      "New Data Upload: 100%|██████████| 22.7kB / 22.7kB, 16.2kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 9.88kB / 9.88kB, 7.06kB/s  \n",
      "New Data Upload: 100%|██████████| 13.2kB / 13.2kB, 9.44kB/s  \n",
      "New Data Upload: 100%|██████████| 13.6kB / 13.6kB, 9.69kB/s  \n",
      "New Data Upload: 100%|██████████| 21.0kB / 21.0kB, 15.0kB/s  \n",
      "New Data Upload: 100%|██████████| 22.7kB / 22.7kB, 16.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.0kB / 21.0kB, 15.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.0kB / 21.0kB, 15.0kB/s  \n",
      "New Data Upload: 100%|██████████| 21.0kB / 21.0kB, 15.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 20.4kB / 20.4kB, 14.6kB/s  \n",
      "New Data Upload: 100%|██████████| 20.4kB / 20.4kB, 14.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 20.4kB / 20.4kB, 14.6kB/s  03<00:01,  3.72 shards/s]\n",
      "New Data Upload: 100%|██████████| 20.4kB / 20.4kB, 14.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.59kB / 9.59kB, 6.85kB/s  03<00:01,  3.72 shards/s]\n",
      "New Data Upload: 100%|██████████| 9.59kB / 9.59kB, 6.85kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.7kB / 21.7kB, 13.6kB/s  \n",
      "New Data Upload: 100%|██████████| 21.7kB / 21.7kB, 13.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.59kB / 9.59kB, 6.85kB/s  \n",
      "New Data Upload: 100%|██████████| 9.59kB / 9.59kB, 6.85kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.7kB / 21.7kB, 13.6kB/s  \n",
      "New Data Upload: 100%|██████████| 21.7kB / 21.7kB, 13.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 16.4kB / 16.4kB, 11.7kB/s  \n",
      "New Data Upload: 100%|██████████| 16.4kB / 16.4kB, 11.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.8kB / 11.8kB, 8.42kB/s  \n",
      "New Data Upload: 100%|██████████| 11.8kB / 11.8kB, 8.42kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.68kB / 9.68kB, 6.05kB/s  \n",
      "New Data Upload: 100%|██████████| 9.68kB / 9.68kB, 6.05kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 16.4kB / 16.4kB, 11.7kB/s  \n",
      "New Data Upload: 100%|██████████| 16.4kB / 16.4kB, 11.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.8kB / 11.8kB, 8.42kB/s  \n",
      "New Data Upload: 100%|██████████| 11.8kB / 11.8kB, 8.42kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.68kB / 9.68kB, 6.05kB/s  \n",
      "New Data Upload: 100%|██████████| 9.68kB / 9.68kB, 6.05kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.16kB / 9.16kB, 7.63kB/s  \n",
      "New Data Upload: 100%|██████████| 9.16kB / 9.16kB, 7.63kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.16kB / 9.16kB, 7.63kB/s  \n",
      "New Data Upload: 100%|██████████| 9.16kB / 9.16kB, 7.63kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.76kB / 9.76kB, 6.10kB/s  \n",
      "New Data Upload: 100%|██████████| 9.76kB / 9.76kB, 6.10kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 9.76kB / 9.76kB, 6.10kB/s  :03<00:00,  7.12 shards/s]\n",
      "New Data Upload: 100%|██████████| 9.76kB / 9.76kB, 6.10kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:03<00:00,  4.32 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 중: interpretation_summary\n",
      "  최소 split 크기: 28, num_proc: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 267.37ba/s]ds/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 280.07ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 267.37ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 280.07ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 271.35ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 271.35ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 115.07ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 115.07ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 88.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 102.02ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 88.53ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 102.02ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 97.40ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.19ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 81.19ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 130.96ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 96.99ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 96.99ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 79.15ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 79.15ba/s]]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 124.88ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 161.39ba/s]\n",
      "\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.81ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 19.24ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 268.64ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.81ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 19.24ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 268.64ba/s]\n",
      "Processing Files (1 / 1): 100%|██████████| 31.5kB / 31.5kB, 22.5kB/s  \n",
      "New Data Upload: 100%|██████████| 31.5kB / 31.5kB, 22.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 27.7kB / 27.7kB, 19.8kB/s  \n",
      "New Data Upload: 100%|██████████| 27.7kB / 27.7kB, 19.8kB/s  1/16 [00:03<00:46,  3.12s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 31.5kB / 31.5kB, 22.5kB/s  \n",
      "New Data Upload: 100%|██████████| 31.5kB / 31.5kB, 22.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 27.7kB / 27.7kB, 19.8kB/s  \n",
      "New Data Upload: 100%|██████████| 27.7kB / 27.7kB, 19.8kB/s  1/16 [00:03<00:46,  3.12s/ shards]\n",
      "Processing Files (1 / 1): 100%|██████████| 20.6kB / 20.6kB, 14.7kB/s  \n",
      "New Data Upload: 100%|██████████| 20.6kB / 20.6kB, 14.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 20.6kB / 20.6kB, 14.7kB/s  \n",
      "New Data Upload: 100%|██████████| 20.6kB / 20.6kB, 14.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 23.2kB / 23.2kB, 16.6kB/s  \n",
      "New Data Upload: 100%|██████████| 23.2kB / 23.2kB, 16.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.2kB / 22.2kB, 15.9kB/s  \n",
      "New Data Upload: 100%|██████████| 22.2kB / 22.2kB, 15.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 23.2kB / 23.2kB, 16.6kB/s  \n",
      "New Data Upload: 100%|██████████| 23.2kB / 23.2kB, 16.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.2kB / 22.2kB, 15.9kB/s  \n",
      "New Data Upload: 100%|██████████| 22.2kB / 22.2kB, 15.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 34.0kB / 34.0kB, 21.3kB/s  \n",
      "New Data Upload: 100%|██████████| 34.0kB / 34.0kB, 21.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 34.0kB / 34.0kB, 21.3kB/s  03<00:04,  2.47 shards/s]\n",
      "New Data Upload: 100%|██████████| 34.0kB / 34.0kB, 21.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.9kB / 21.9kB, 13.7kB/s  03<00:04,  2.47 shards/s]\n",
      "New Data Upload: 100%|██████████| 21.9kB / 21.9kB, 13.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 21.9kB / 21.9kB, 13.7kB/s  \n",
      "New Data Upload: 100%|██████████| 21.9kB / 21.9kB, 13.7kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 34.5kB / 34.5kB, 21.5kB/s  \n",
      "New Data Upload: 100%|██████████| 34.5kB / 34.5kB, 21.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 34.5kB / 34.5kB, 21.5kB/s  \n",
      "New Data Upload: 100%|██████████| 34.5kB / 34.5kB, 21.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 27.1kB / 27.1kB, 17.0kB/s  \n",
      "New Data Upload: 100%|██████████| 27.1kB / 27.1kB, 17.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.1kB / 22.1kB, 13.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 27.1kB / 27.1kB, 17.0kB/s  \n",
      "New Data Upload: 100%|██████████| 27.1kB / 27.1kB, 17.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.1kB / 22.1kB, 13.8kB/s  \n",
      "New Data Upload: 100%|██████████| 22.1kB / 22.1kB, 13.8kB/s  \n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 30.0kB / 30.0kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 30.0kB / 30.0kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 32.6kB / 32.6kB, 20.4kB/s  \n",
      "New Data Upload: 100%|██████████| 32.6kB / 32.6kB, 20.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 30.0kB / 30.0kB, 18.8kB/s  \n",
      "New Data Upload: 100%|██████████| 30.0kB / 30.0kB, 18.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 32.6kB / 32.6kB, 20.4kB/s  \n",
      "New Data Upload: 100%|██████████| 32.6kB / 32.6kB, 20.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.3kB / 22.3kB, 13.9kB/s  \n",
      "New Data Upload: 100%|██████████| 22.3kB / 22.3kB, 13.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 22.3kB / 22.3kB, 13.9kB/s  :03<00:00,  5.91 shards/s]\n",
      "New Data Upload: 100%|██████████| 22.3kB / 22.3kB, 13.9kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 24.1kB / 24.1kB, 15.1kB/s  :03<00:00,  5.91 shards/s]\n",
      "New Data Upload: 100%|██████████| 24.1kB / 24.1kB, 15.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 24.1kB / 24.1kB, 15.1kB/s  \n",
      "New Data Upload: 100%|██████████| 24.1kB / 24.1kB, 15.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.3kB / 18.3kB, 11.4kB/s  \n",
      "New Data Upload: 100%|██████████| 18.3kB / 18.3kB, 11.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.3kB / 18.3kB, 11.4kB/s  \n",
      "New Data Upload: 100%|██████████| 18.3kB / 18.3kB, 11.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.2kB / 25.2kB, 10.5kB/s  \n",
      "New Data Upload: 100%|██████████| 25.2kB / 25.2kB, 10.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 25.2kB / 25.2kB, 10.5kB/s  :04<00:00,  5.63 shards/s]\n",
      "New Data Upload: 100%|██████████| 25.2kB / 25.2kB, 10.5kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:04<00:00,  3.73 shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Uploading the dataset shards (num_proc=16):   0%|          | 0/16 [00:00<?, ? shards/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 74.16ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.65ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 68.14ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 74.16ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 131.65ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 68.14ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 52.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 43.93ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 43.93ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 54.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 69.52ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 56.68ba/s]\n",
      "\n",
      "Creating parquet from Arrow format:   0%|          | 0/1 [00:00<?, ?ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 69.52ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 56.68ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 51.36ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 22.48ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 22.48ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 10.08ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 156.97ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 18.89ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 10.59ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 10.08ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 156.97ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 18.89ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 11.57ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 10.59ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 86.24ba/s]\n",
      "\n",
      "Processing Files (1 / 1): 100%|██████████| 16.8kB / 16.8kB, 14.0kB/s  \n",
      "New Data Upload: 100%|██████████| 16.8kB / 16.8kB, 14.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 16.8kB / 16.8kB, 14.0kB/s  02<00:43,  2.91s/ shards]\n",
      "New Data Upload: 100%|██████████| 16.8kB / 16.8kB, 14.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 6.19kB / 6.19kB, 5.15kB/s  02<00:43,  2.91s/ shards]\n",
      "New Data Upload: 100%|██████████| 6.19kB / 6.19kB, 5.15kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 6.19kB / 6.19kB, 5.15kB/s  \n",
      "New Data Upload: 100%|██████████| 6.19kB / 6.19kB, 5.15kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.8kB / 19.8kB, 14.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.6kB / 19.6kB, 14.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.7kB / 18.7kB, 13.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 17.6kB / 17.6kB, 12.6kB/s  \n",
      "New Data Upload: 100%|██████████| 19.6kB / 19.6kB, 14.0kB/s  \n",
      "New Data Upload: 100%|██████████| 17.6kB / 17.6kB, 12.6kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.6kB / 19.6kB, 14.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.7kB / 18.7kB, 13.3kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 17.6kB / 17.6kB, 12.6kB/s  \n",
      "New Data Upload: 100%|██████████| 19.6kB / 19.6kB, 14.0kB/s  \n",
      "New Data Upload: 100%|██████████| 17.6kB / 17.6kB, 12.6kB/s  \n",
      "New Data Upload: 100%|██████████| 18.7kB / 18.7kB, 13.3kB/s  3/16 [00:03<00:10,  1.24 shards/s]\n",
      "New Data Upload: 100%|██████████| 19.8kB / 19.8kB, 14.1kB/s  \n",
      "\n",
      "New Data Upload: 100%|██████████| 18.7kB / 18.7kB, 13.3kB/s  3/16 [00:03<00:10,  1.24 shards/s]\n",
      "New Data Upload: 100%|██████████| 19.8kB / 19.8kB, 14.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.5kB / 11.5kB, 8.20kB/s  \n",
      "New Data Upload: 100%|██████████| 11.5kB / 11.5kB, 8.20kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 11.5kB / 11.5kB, 8.20kB/s  \n",
      "New Data Upload: 100%|██████████| 11.5kB / 11.5kB, 8.20kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.2kB / 18.2kB, 15.2kB/s  \n",
      "New Data Upload: 100%|██████████| 18.2kB / 18.2kB, 15.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.5kB / 19.5kB, 16.2kB/s  03<00:01,  4.17 shards/s]\n",
      "New Data Upload: 100%|██████████| 19.5kB / 19.5kB, 16.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.7kB / 19.7kB, 16.4kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.2kB / 18.2kB, 15.2kB/s  \n",
      "New Data Upload: 100%|██████████| 18.2kB / 18.2kB, 15.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.5kB / 19.5kB, 16.2kB/s  03<00:01,  4.17 shards/s]\n",
      "New Data Upload: 100%|██████████| 19.5kB / 19.5kB, 16.2kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.6kB / 10.6kB, 7.55kB/s  \n",
      "New Data Upload: 100%|██████████| 10.6kB / 10.6kB, 7.55kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.0kB / 18.0kB, 12.8kB/s  \n",
      "New Data Upload: 100%|██████████| 18.0kB / 18.0kB, 12.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.6kB / 10.6kB, 7.55kB/s  \n",
      "New Data Upload: 100%|██████████| 10.6kB / 10.6kB, 7.55kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.0kB / 18.0kB, 12.8kB/s  \n",
      "New Data Upload: 100%|██████████| 18.0kB / 18.0kB, 12.8kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 14.7kB / 14.7kB, 10.5kB/s  \n",
      "New Data Upload: 100%|██████████| 14.7kB / 14.7kB, 10.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.2kB / 18.2kB, 13.0kB/s  \n",
      "New Data Upload: 100%|██████████| 18.2kB / 18.2kB, 13.0kB/s  \n",
      "New Data Upload: 100%|██████████| 14.7kB / 14.7kB, 10.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 18.2kB / 18.2kB, 13.0kB/s  \n",
      "New Data Upload: 100%|██████████| 18.2kB / 18.2kB, 13.0kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.7kB / 19.7kB, 14.1kB/s  \n",
      "New Data Upload: 100%|██████████| 19.7kB / 19.7kB, 14.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 19.7kB / 19.7kB, 14.1kB/s  :03<00:00,  7.93 shards/s]\n",
      "New Data Upload: 100%|██████████| 19.7kB / 19.7kB, 14.1kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 20.3kB / 20.3kB, 14.5kB/s  :03<00:00,  7.93 shards/s]\n",
      "New Data Upload: 100%|██████████| 20.3kB / 20.3kB, 14.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 20.3kB / 20.3kB, 14.5kB/s  \n",
      "New Data Upload: 100%|██████████| 20.3kB / 20.3kB, 14.5kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.4kB / 10.4kB, 7.46kB/s  \n",
      "New Data Upload: 100%|██████████| 10.4kB / 10.4kB, 7.46kB/s  \n",
      "Processing Files (1 / 1): 100%|██████████| 10.4kB / 10.4kB, 7.46kB/s  \n",
      "New Data Upload: 100%|██████████| 10.4kB / 10.4kB, 7.46kB/s  \n",
      "Uploading the dataset shards (num_proc=16): 100%|██████████| 16/16 [00:03<00:00,  4.38 shards/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "업로드 스크립트 준비 완료\n",
      "✓ 리포지토리: https://huggingface.co/datasets/brainer/civil-law-ko-v2\n"
     ]
    }
   ],
   "source": [
    "# HuggingFace Hub 업로드 (선택사항)\n",
    "# 실행하려면 주석 해제하고 토큰/리포지토리명 설정\n",
    "\n",
    "from huggingface_hub import login\n",
    "import os\n",
    "\n",
    "# 로그인 (환경변수 또는 직접 입력)\n",
    "# login(token=\"your_hf_token\")\n",
    "\n",
    "# 서브셋별로 config 분리하여 업로드\n",
    "repo_name = \"brainer/civil-law-ko-v2\"\n",
    "\n",
    "# typed_datasets의 모든 키를 configs로 매핑\n",
    "configs = {}\n",
    "for dataset_key, dataset_dict in typed_datasets.items():\n",
    "    configs[dataset_key] = dataset_dict\n",
    "    print(f\"Config 추가: {dataset_key}\")\n",
    "\n",
    "print(f\"\\n총 {len(configs)}개의 config 준비됨:\")\n",
    "for config_name in configs.keys():\n",
    "    print(f\"  - {config_name}\")\n",
    "\n",
    "# 각 config별로 업로드\n",
    "for config_name, dataset in configs.items():\n",
    "    print(f\"\\n업로드 중: {config_name}\")\n",
    "    \n",
    "    # 데이터셋 크기에 따라 num_proc 조정\n",
    "    min_size = min(len(split_ds) for split_ds in dataset.values())\n",
    "    # num_proc는 최소 split 크기와 CPU 수 중 작은 값으로 설정 (최소 1)\n",
    "    safe_num_proc = max(1, min(min_size, os.cpu_count() or 1))\n",
    "    \n",
    "    print(f\"  최소 split 크기: {min_size}, num_proc: {safe_num_proc}\")\n",
    "    \n",
    "    dataset.push_to_hub(\n",
    "        repo_name,\n",
    "        config_name=config_name,\n",
    "        num_proc=safe_num_proc\n",
    "    )\n",
    "\n",
    "print(\"\\n업로드 스크립트 준비 완료\")\n",
    "print(f\"✓ 리포지토리: https://huggingface.co/datasets/{repo_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31467b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "law",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
